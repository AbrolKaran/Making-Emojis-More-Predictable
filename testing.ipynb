{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-27 12:41:15.166960: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-11-27 12:41:15.166992: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flask.helpers import flash\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "import preprocessor as p\n",
    "import re\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "from flask import Flask, render_template, request\n",
    "from gensim import models\n",
    "from collections import defaultdict\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, RNN, Dense, Dropout, Embedding, RNN, Bidirectional, Add, merge, concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'@user','',text)\n",
    "    text  = \"\".join([char.lower() for char in text if char not in string.punctuation])\n",
    "    text  = \"\".join([char.lower() for char in text if char not in ['â€¦','\\n']])\n",
    "    text = re.sub('[0-9]+', '', text)\n",
    "    # text = ''.join(i for i in text if ord(i)<128)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = word_tokenize(text)    \n",
    "    for i in range(len(text)):\n",
    "        word = text[i]\n",
    "        newword = word[0]\n",
    "        prev = word[0]\n",
    "        prev_cnt = 0\n",
    "        for j in range(1,len(word)):\n",
    "            if word[j] == prev:\n",
    "                prev_cnt+=1\n",
    "                if prev_cnt < 2:\n",
    "                    newword += word[j]\n",
    "            else:\n",
    "                newword += word[j]\n",
    "                prev = word[j]\n",
    "                prev_cnt = 0\n",
    "                \n",
    "        text[i] = newword\n",
    "\n",
    "    text = [word for word in text if word not in stopword]\n",
    "    #text = [str(TextBlob(word).correct()) for word in text]\n",
    "    text = [word for word in text if word not in stopword]\n",
    "    # text = [ps.stem(word) for word in text]\n",
    "    # text = [word for word in text if 10>len(word)>2]\n",
    "    # for word in text:\n",
    "    #     if len(word)<=2:\n",
    "    #         print(word)\n",
    "    new_text = \" \".join([word for word in text])\n",
    "    return \"tweet \" + new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gloveEmbs = open('./src/glove.twitter.27B.200d.txt', encoding='utf-8')\n",
    "\n",
    "\n",
    "embeddings = {}\n",
    "for line in gloveEmbs:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings[word] = coefs\n",
    "gloveEmbs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeddingOutput(X):\n",
    "    \"\"\"\n",
    "    X: input matrix\n",
    "    \"\"\"\n",
    "    maxLen = 10\n",
    "    embDim = 200\n",
    "    embOutput = np.zeros((len(X), maxLen, embDim))\n",
    "    for i in range(len(X)):\n",
    "        X[i] = X[i].split()\n",
    "        for j in range(maxLen):\n",
    "            try:\n",
    "                embOutput[i][j] = embeddings[X[i][j].lower()]\n",
    "            except:\n",
    "                embOutput[i][j] = np.zeros((embDim, ))\n",
    "    return embOutput\n",
    "\n",
    "text = \"hello world\"\n",
    "\n",
    "def addWE(text,embedding,bow_test):\n",
    "    emb_text = embeddingOutput([text])\n",
    "    new_text = np.concatenate((emb_text, bow_test), axis=1)\n",
    "    return new_text\n",
    "\n",
    "\n",
    "def get_prediction(text,model):\n",
    "    p_processed = p.clean(text)\n",
    "    finPre = clean_text(p_processed)\n",
    "    text = embeddingOutput(finPre)\n",
    "    prediction = model.predict(bow_test)\n",
    "\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-27 12:42:21.176813: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-11-27 12:42:21.177093: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-11-27 12:42:21.177137: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (karan--dell): /proc/driver/nvidia/version does not exist\n",
      "2021-11-27 12:42:21.177540: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(10, 200))) #hidden state has 64 dims\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(20, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./src/finalModels/modelPickles/lstmBestLoss.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "stopword += ['yr', 'year', 'woman', 'man', 'girl','boy','one', 'two', 'sixteen', 'yearold', 'fu', 'weeks', 'week',\n",
    "            'treatment', 'associated', 'patients', 'may','day', 'case','old']\n",
    "mapping = {0:'&#x2764',1:'&#x1F60D',2:'&#x1F602',3:'&#x1F495',4:'&#x1F525', 5:'&#x1F60A',6:'&#x1F60E',7:'&#x2728',8:'&#x1F499',9:'&#x1F618',10:'&#x1F4F7',11:'&#x1F1F8',12:'&#x2600',13:'&#x1F49C',14:'&#x1F609',15:'&#x1F4AF',16:'&#x1F601',17:'&#x1F384',18:'&#x1F4F8',19:'&#x1F61C'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet christmas\n",
      "[[[ 0.56392998  0.63700998 -0.39173999 ...  0.22901     0.052185\n",
      "   -0.49693999]\n",
      "  [-0.29572999  0.11136     0.37964001 ... -0.39938    -0.11078\n",
      "    0.14462   ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "text = \"christmas\"\n",
    "\n",
    "p_processed = p.clean(text)\n",
    "finPre = clean_text(p_processed)\n",
    "print(finPre)\n",
    "text = embeddingOutput([finPre])\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.3026679e-01, 3.0972028e-02, 1.3838872e-02, 1.1406416e-02,\n",
       "        5.5857818e-03, 1.3492793e-02, 2.7900359e-03, 1.1499935e-02,\n",
       "        3.3656484e-03, 7.9218326e-03, 3.0642971e-03, 1.1463417e-03,\n",
       "        3.0885899e-04, 2.5654647e-03, 3.4759697e-03, 3.1451051e-04,\n",
       "        7.6851249e-03, 7.4703693e-01, 1.4981430e-03, 1.7641491e-03]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17]\n"
     ]
    }
   ],
   "source": [
    "pred = np.argmax(pred,axis=1)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

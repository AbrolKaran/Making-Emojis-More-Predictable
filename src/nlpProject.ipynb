{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_a4PvfiovN4l"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from collections import defaultdict\n",
        "from nltk.tokenize import word_tokenize\n",
        "import preprocessor as p\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import re\n",
        "from nltk.stem.snowball import EnglishStemmer\n",
        "import pickle\n",
        "from gensim import models\n",
        "from gensim.models import Word2Vec\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fPvh69VLvabK"
      },
      "outputs": [],
      "source": [
        "\n",
        "class TfidfEmbeddingVectorizer(object):\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.modelweight = None\n",
        "        for i in model:\n",
        "            self.dim = len(model[i])\n",
        "            break\n",
        "        # self.dim = len(model[model.keys()[0]])\n",
        "\n",
        "    def fit(self, X):\n",
        "        tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
        "        tfidf.fit(X)\n",
        "        # if a word was never seen - it must be at least as infrequent\n",
        "        # as any of the known words - so the default idf is the max of \n",
        "        # known idf's\n",
        "        max_idf = max(tfidf.idf_)\n",
        "        self.modelweight = defaultdict(\n",
        "\t\t    lambda: max_idf,\n",
        "\t\t    [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return np.array([\n",
        "\t\t        np.mean([self.model[w] * self.modelweight[w]\n",
        "\t\t                 for w in words if w in self.model] or\n",
        "\t\t                [np.zeros(self.dim)], axis=0)\n",
        "\t\t        for words in X\n",
        "\t\t    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZFGgoGNmvjDx"
      },
      "outputs": [],
      "source": [
        "def word_embeddings(tweets, embedding):\n",
        "    if embedding == \"word2vec\":\n",
        "        X = word2vec(tweets)\n",
        "        w2v = models.Word2Vec(X, vector_size=200, window=5, sg=0)\n",
        "        model = dict(zip(w2v.wv.index_to_key, w2v.wv.vectors))\n",
        "        \n",
        "    elif embedding == \"glove\":\n",
        "        with open(\"./glove.twitter.27B.200d.txt\", \"rb\") as lines:\n",
        "            model = {line.split()[0]: np.array(map(float, line.split()[1:]))\n",
        "                for line in lines}\n",
        "\n",
        "\n",
        "    vec = TfidfEmbeddingVectorizer(model)\n",
        "    vec.fit(tweets)\n",
        "    matrix = vec.transform(tweets)\n",
        "\n",
        "    return matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "x6FCYqiAvkpY"
      },
      "outputs": [],
      "source": [
        "def word2vec(tweets):\n",
        "    texts = []\n",
        "\n",
        "    for tweet in tweets:\n",
        "        texts.append(tweet.split())\n",
        "\n",
        "    return texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuMHUUCIv8VV",
        "outputId": "abff7132-85c4-46d0-a9f9-6d16c33ca0e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tweet step explore ellis island cafe\n",
            "tweet en pelham parkway\n",
            "tweet little throwback favourite person water wall\n"
          ]
        }
      ],
      "source": [
        "train_text = pd.read_table('./preprocessed_100k_train_text.txt', engine=\"python-fwf\")\n",
        "train_text = train_text['Text']\n",
        "print(train_text.loc[0])\n",
        "\n",
        "test_text = pd.read_table('./preprocessed_test_text.txt', engine=\"python-fwf\")\n",
        "test_text = test_text['Text']\n",
        "print(test_text.loc[0])\n",
        "\n",
        "trial_text = pd.read_table('./preprocessed_trial_text.txt', engine=\"python-fwf\")\n",
        "trial_text = trial_text['Text']\n",
        "print(trial_text.loc[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100000/100000 [00:00<00:00, 1168700.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50000/50000 [00:00<00:00, 964775.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50000/50000 [00:00<00:00, 1015417.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train_emoji = (open(\"./../Dataset/train/us_train.labels\", \"r\").readlines())\n",
        "train_emoji = train_emoji[:100000]\n",
        "for i in tqdm(range(len(train_emoji))):\n",
        "    train_emoji[i] = int(train_emoji[i][0])\n",
        "train_labels = pd.Series((np.array(train_emoji)).astype('int8'))\n",
        "print(train_labels.loc[0])\n",
        "\n",
        "test_emoji = (open(\"./../Dataset/test/us_test.labels\", \"r\").readlines())\n",
        "for i in tqdm(range(len(test_emoji))):\n",
        "    test_emoji[i] = int(test_emoji[i][0])\n",
        "test_labels = pd.Series((np.array(test_emoji)).astype('int8'))\n",
        "print(test_labels.loc[0])\n",
        "\n",
        "trial_emoji = (open(\"./../Dataset/trial/us_trial.labels\", \"r\").readlines())\n",
        "for i in tqdm(range(len(trial_emoji))):\n",
        "    trial_emoji[i] = int(trial_emoji[i][0])\n",
        "trial_labels = pd.Series((np.array(trial_emoji)).astype('int8'))\n",
        "print(trial_labels.loc[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NMN8tZfwd8-",
        "outputId": "3a6b3761-3b1e-4ce9-d9ad-01d18148822e"
      },
      "outputs": [],
      "source": [
        "embedding = \"word2vec\"\n",
        "emb_train = word_embeddings(train_text, embedding)\n",
        "emb_trial = word_embeddings(trial_text, embedding)\n",
        "emb_test = word_embeddings(test_text, embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iYYGBVLRwgm7"
      },
      "outputs": [],
      "source": [
        "vec = TfidfVectorizer(min_df=1, ngram_range=(1,3), decode_error='ignore', max_features=2000)\n",
        "bow_train = vec.fit_transform(train_text).toarray()\n",
        "bow_trial = vec.transform(trial_text).toarray()\n",
        "bow_test =  vec.transform(test_text).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nBplwTc6yZHH"
      },
      "outputs": [],
      "source": [
        "train = np.concatenate((emb_train, bow_train), axis=1)\n",
        "trial = np.concatenate((emb_trial, bow_trial), axis=1)\n",
        "test = np.concatenate((emb_test, bow_test), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.save('100k_t2_train',train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.save('100k_t2_trial',trial)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.save('100k_t2_test',test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWhuZDqr0BWT",
        "outputId": "8e619067-a5ff-4217-a674-abaa4f2f7517"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50000, 2200)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trial.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "UEbzu0zK0QGr"
      },
      "outputs": [],
      "source": [
        "from sklearn import svm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "bATCfxYx0UZW"
      },
      "outputs": [],
      "source": [
        "SVM = svm.SVC(kernel='linear', max_iter=1000, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "i0WsZIrB0g7J"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "6vDNQkrs0m5m"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0WVg0xs7FPm",
        "outputId": "284ba405-0e11-476a-908b-870687419610"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((80000, 3700), (80000,), (20000, 3700), (20000,))"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "rflq1M_W2ts8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LibSVM]WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1976.053429, rho = 0.281430\n",
            "nSV = 2000, nBSV = 2000\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1955.333710, rho = 0.130612\n",
            "nSV = 2000, nBSV = 2000\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1949.966687, rho = 0.552158\n",
            "nSV = 1995, nBSV = 1991\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1931.179913, rho = 0.107232\n",
            "nSV = 1998, nBSV = 1994\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1948.780973, rho = 1.631290\n",
            "nSV = 2000, nBSV = 1998\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1892.548038, rho = 1.695760\n",
            "nSV = 1950, nBSV = 1946\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1932.143312, rho = 1.908811\n",
            "nSV = 1998, nBSV = 1994\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1942.298560, rho = -1.412960\n",
            "nSV = 1998, nBSV = 1994\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1941.883454, rho = 0.802700\n",
            "nSV = 2000, nBSV = 1998\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1966.895846, rho = -1.635581\n",
            "nSV = 2000, nBSV = 1998\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1951.904132, rho = 0.178959\n",
            "nSV = 2000, nBSV = 1998\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1949.347849, rho = 1.254663\n",
            "nSV = 1998, nBSV = 1994\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1951.534889, rho = -1.452195\n",
            "nSV = 1999, nBSV = 1995\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1953.275003, rho = 1.535583\n",
            "nSV = 2000, nBSV = 1998\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1931.480390, rho = -1.055035\n",
            "nSV = 1987, nBSV = 1981\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1942.879620, rho = 0.415614\n",
            "nSV = 1998, nBSV = 1992\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1937.220281, rho = 0.382934\n",
            "nSV = 1995, nBSV = 1987\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1904.878955, rho = -0.096596\n",
            "nSV = 2000, nBSV = 2000\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1923.394948, rho = -1.213562\n",
            "nSV = 2000, nBSV = 1998\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1927.574571, rho = 0.801947\n",
            "nSV = 2000, nBSV = 1998\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1921.400374, rho = 0.658960\n",
            "nSV = 1995, nBSV = 1993\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1885.887487, rho = 0.749626\n",
            "nSV = 1996, nBSV = 1994\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1881.104213, rho = 0.239524\n",
            "nSV = 1994, nBSV = 1988\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1890.467138, rho = 0.364531\n",
            "nSV = 2000, nBSV = 1998\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1850.660541, rho = -0.361691\n",
            "nSV = 2000, nBSV = 2000\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1909.857381, rho = 0.244729\n",
            "nSV = 2000, nBSV = 2000\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1883.973694, rho = 1.492383\n",
            "nSV = 2000, nBSV = 1998\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1878.932157, rho = 0.548517\n",
            "nSV = 1995, nBSV = 1991\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1901.773210, rho = -1.618991\n",
            "nSV = 2000, nBSV = 2000\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1906.882613, rho = -1.011705\n",
            "nSV = 2000, nBSV = 2000\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1862.259142, rho = 0.796971\n",
            "nSV = 1996, nBSV = 1992\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1894.518364, rho = -0.078771\n",
            "nSV = 1994, nBSV = 1988\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1845.599608, rho = 0.009046\n",
            "nSV = 1994, nBSV = 1990\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1827.997746, rho = 0.438294\n",
            "nSV = 1995, nBSV = 1985\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1776.656238, rho = -0.675644\n",
            "nSV = 1969, nBSV = 1959\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1904.228713, rho = 1.197581\n",
            "nSV = 2000, nBSV = 2000\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1884.359219, rho = 1.352411\n",
            "nSV = 2000, nBSV = 1998\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1884.997532, rho = -0.169251\n",
            "nSV = 2000, nBSV = 2000\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1886.046525, rho = -1.279058\n",
            "nSV = 2000, nBSV = 2000\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1864.983427, rho = 1.124942\n",
            "nSV = 1993, nBSV = 1985\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1848.122723, rho = 0.884193\n",
            "nSV = 1987, nBSV = 1983\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1847.933734, rho = 0.292094\n",
            "nSV = 1987, nBSV = 1980\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1846.554526, rho = -0.823913\n",
            "nSV = 1994, nBSV = 1990\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1821.507169, rho = 0.803499\n",
            "nSV = 2000, nBSV = 1998\n",
            "WARN: libsvm Solver reached max_iter\n",
            "optimization finished, #iter = 1000\n",
            "obj = -1855.960774, rho = 0.980684\n",
            "nSV = 2000, nBSV = 1996\n",
            "Total nSV = 36871\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/karan/.local/lib/python3.8/site-packages/sklearn/svm/_base.py:284: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "SVC(kernel='linear', max_iter=1000, verbose=True)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "SVM.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "svm_parameters = np.array(SVM.get_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.save('svm_parameters',svm_parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = SVM.predict(X_train)\n",
        "print(accuracy_score(predictions,y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "nlpProject.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

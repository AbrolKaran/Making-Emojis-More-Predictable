{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sklearn.metrics as met\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = np.load('../../fin_t2_train.npy')\n",
    "trialData = np.load('../../fin_t2_trial.npy')\n",
    "testData = np.load('../../fin_t2_test.npy')\n",
    "\n",
    "noWEtrainData = np.load('../../fin_noWE_t2_train.npy')\n",
    "noWEtrialData = np.load('../../fin_noWE_t2_trial.npy')\n",
    "noWEtestData = np.load('../../fin_noWE_t2_test.npy')\n",
    "\n",
    "trainLabels = open('../../../dataFinal/finalTrainLabels.labels', 'r').readlines()\n",
    "trialLabels = open('../../../dataFinal/finalDevLabels.labels','r').readlines()\n",
    "testLabels = open('../../../dataFinal/finalTestLabels.labels', 'r').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69992/69992 [00:00<00:00, 1478379.47it/s]\n",
      "100%|██████████| 20000/20000 [00:00<00:00, 1645728.64it/s]\n",
      "100%|██████████| 10008/10008 [00:00<00:00, 1704010.49it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(trainLabels))):\n",
    "    trainLabels[i] = int(trainLabels[i])\n",
    "for i in tqdm(range(len(testLabels))):\n",
    "    testLabels[i] = int(testLabels[i])\n",
    "for i in tqdm(range(len(trialLabels))):\n",
    "    trialLabels[i] = int(trialLabels[i])\n",
    "\n",
    "trainLabels = np.array(trainLabels)\n",
    "testLabels = np.array(testLabels)\n",
    "trialLabels = np.array(trialLabels)\n",
    "\n",
    "trainLabels = trainLabels.reshape((-1, ))\n",
    "testLabels = testLabels.reshape((-1, ))\n",
    "trialLabels = trialLabels.reshape((-1, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('svm_score.txt','a') as file:\n",
    "    file.write(\"SVM - Bag of Words + Word Embeddings:\\n\\n\")\n",
    "\n",
    "    for c in [0.1,0.2,0.25,0.3,0.35,0.4,0.5,1,2,5]:\n",
    "        file.write(\"C = {}:\".format(c))\n",
    "        model = pickle.load(open('./models/SVM_linear_{}'.format(c),'rb'))\n",
    "        train_predict = model.predict(trainData)\n",
    "        trial_predict = model.predict(trialData)\n",
    "        test_predict = model.predict(testData)\n",
    "        train_acc = met.accuracy_score(trainLabels,train_predict)\n",
    "        trial_acc = met.accuracy_score(trialLabels,trial_predict)\n",
    "        test_acc = met.accuracy_score(testLabels,test_predict)\n",
    "        train_prec = met.precision_score(trainLabels,train_predict,average='weighted')\n",
    "        trial_prec = met.precision_score(trialLabels,trial_predict,average='weighted')\n",
    "        test_prec = met.precision_score(testLabels,test_predict,average='weighted')\n",
    "        train_rec = met.recall_score(trainLabels, train_predict,average='weighted')\n",
    "        trial_rec = met.recall_score(trialLabels, trial_predict,average='weighted')\n",
    "        test_rec = met.recall_score(testLabels, test_predict,average='weighted')\n",
    "        train_f1 = met.f1_score(trainLabels,train_predict,average='weighted')\n",
    "        trial_f1 = met.f1_score(trialLabels,trial_predict,average='weighted')\n",
    "        test_f1 = met.f1_score(testLabels,test_predict,average='weighted')\n",
    "\n",
    "        file.write(\"\\n\\tTrain Accuracy: {}\".format(train_acc))\n",
    "        file.write(\"\\n\\tTrain Precision: {}\".format(train_prec))\n",
    "        file.write(\"\\n\\tTrain Recall: {}\".format(train_rec))\n",
    "        file.write(\"\\n\\tTrain F1: {}\".format(train_f1))\n",
    "        file.write(\"\\n\")\n",
    "        file.write(\"\\n\\tTrial Accuracy: {}\".format(trial_acc))\n",
    "        file.write(\"\\n\\tTrial Precision: {}\".format(trial_prec))\n",
    "        file.write(\"\\n\\tTrial Recall: {}\".format(trial_rec))\n",
    "        file.write(\"\\n\\tTrial F1: {}\".format(trial_f1))\n",
    "        file.write(\"\\n\")\n",
    "        file.write(\"\\n\\tTest Accuracy: {}\".format(test_acc))\n",
    "        file.write(\"\\n\\tTest Precision: {}\".format(test_prec))\n",
    "        file.write(\"\\n\\tTest Recall: {}\".format(test_rec))\n",
    "        file.write(\"\\n\\tTest F1: {}\".format(test_f1))\n",
    "        file.write(\"\\n\\n\")\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('svm_score.txt','a') as file:\n",
    "    file.write(\"\\n\\nSVM - Bag of Words only:\\n\\n\")\n",
    "\n",
    "    for c in [0.1,0.2,0.25,0.3,0.35,0.4,0.5,1,2,5]:\n",
    "        file.write(\"C = {}:\".format(c))\n",
    "        model = pickle.load(open('./models/noWE_SVM_linear_{}'.format(c),'rb'))\n",
    "        train_predict = model.predict(noWEtrainData)\n",
    "        trial_predict = model.predict(noWEtrialData)\n",
    "        test_predict = model.predict(noWEtestData)\n",
    "        train_acc = met.accuracy_score(trainLabels,train_predict)\n",
    "        trial_acc = met.accuracy_score(trialLabels,trial_predict)\n",
    "        test_acc = met.accuracy_score(testLabels,test_predict)\n",
    "        train_prec = met.precision_score(trainLabels,train_predict,average='weighted')\n",
    "        trial_prec = met.precision_score(trialLabels,trial_predict,average='weighted')\n",
    "        test_prec = met.precision_score(testLabels,test_predict,average='weighted')\n",
    "        train_rec = met.recall_score(trainLabels, train_predict,average='weighted')\n",
    "        trial_rec = met.recall_score(trialLabels, trial_predict,average='weighted')\n",
    "        test_rec = met.recall_score(testLabels, test_predict,average='weighted')\n",
    "        train_f1 = met.f1_score(trainLabels,train_predict,average='weighted')\n",
    "        trial_f1 = met.f1_score(trialLabels,trial_predict,average='weighted')\n",
    "        test_f1 = met.f1_score(testLabels,test_predict,average='weighted')\n",
    "\n",
    "        file.write(\"\\n\\tTrain Accuracy: {}\".format(train_acc))\n",
    "        file.write(\"\\n\\tTrain Precision: {}\".format(train_prec))\n",
    "        file.write(\"\\n\\tTrain Recall: {}\".format(train_rec))\n",
    "        file.write(\"\\n\\tTrain F1: {}\".format(train_f1))\n",
    "        file.write(\"\\n\")\n",
    "        file.write(\"\\n\\tTrial Accuracy: {}\".format(trial_acc))\n",
    "        file.write(\"\\n\\tTrial Precision: {}\".format(trial_prec))\n",
    "        file.write(\"\\n\\tTrial Recall: {}\".format(trial_rec))\n",
    "        file.write(\"\\n\\tTrial F1: {}\".format(trial_f1))\n",
    "        file.write(\"\\n\")\n",
    "        file.write(\"\\n\\tTest Accuracy: {}\".format(test_acc))\n",
    "        file.write(\"\\n\\tTest Precision: {}\".format(test_prec))\n",
    "        file.write(\"\\n\\tTest Recall: {}\".format(test_rec))\n",
    "        file.write(\"\\n\\tTest F1: {}\".format(test_f1))\n",
    "        file.write(\"\\n\\n\")\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKo1Y_z7zr3g"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qT6sCwF1zuMJ"
      },
      "outputs": [],
      "source": [
        "trainData = open('../../../dataFinal/preprocessed_train_text.txt', 'r').readlines()\n",
        "trainLabels = open('../../../dataFinal/finalTrainLabels.labels', 'r').readlines()\n",
        "testData = open('../../../dataFinal/preprocessed_test_text.txt', 'r').readlines()\n",
        "testLabels = open('../../../dataFinal/finalTestLabels.labels', 'r').readlines()\n",
        "validData = open('../../../dataFinal/preprocessed_trial_text.txt', 'r').readlines()\n",
        "validLabels = open('../../../dataFinal/finalDevLabels.labels', 'r').readlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAt43ulT0BkC",
        "outputId": "4b71c503-75d2-46b6-ec81-32ec2d3e5dac"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 69993/69993 [00:00<00:00, 1653879.72it/s]\n",
            "100%|██████████| 20001/20001 [00:00<00:00, 1464718.27it/s]\n",
            "100%|██████████| 10009/10009 [00:00<00:00, 1801905.26it/s]\n"
          ]
        }
      ],
      "source": [
        "for i in tqdm(range(len(trainData))):\n",
        "    trainData[i] = trainData[i][:-1]\n",
        "for i in tqdm(range(len(testData))):\n",
        "    testData[i] = testData[i][:-1]\n",
        "for i in tqdm(range(len(validData))):\n",
        "    validData[i] = validData[i][:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-f9qTnaV0Y-2",
        "outputId": "c6fe648e-b244-4bcb-a211-6733a4757201"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 69992/69992 [00:00<00:00, 1302765.24it/s]\n",
            "100%|██████████| 20000/20000 [00:00<00:00, 1040370.08it/s]\n",
            "100%|██████████| 10008/10008 [00:00<00:00, 1411642.27it/s]\n"
          ]
        }
      ],
      "source": [
        "for i in tqdm(range(len(trainLabels))):\n",
        "    trainLabels[i] = int(trainLabels[i])\n",
        "for i in tqdm(range(len(testLabels))):\n",
        "    testLabels[i] = int(testLabels[i])\n",
        "for i in tqdm(range(len(validLabels))):\n",
        "    validLabels[i] = int(validLabels[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb3_PWHD0asK"
      },
      "outputs": [],
      "source": [
        "trainData = trainData[1:]\n",
        "testData = testData[1:]\n",
        "validData = validData[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMnAsBYY0cOW"
      },
      "outputs": [],
      "source": [
        "trainLabels = np.array(trainLabels)\n",
        "testLabels = np.array(testLabels)\n",
        "validLabels = np.array(validLabels)\n",
        "trainLabels = trainLabels.reshape((-1, ))\n",
        "testLabels = testLabels.reshape((-1, ))\n",
        "validLabels = validLabels.reshape((-1, ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAVSn33o5fa4"
      },
      "outputs": [],
      "source": [
        "gloveEmbs = open('../../glove.twitter.27B.200d.txt', encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDWdtgqc5mV3"
      },
      "outputs": [],
      "source": [
        "embeddings = {}\n",
        "for line in gloveEmbs:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings[word] = coefs\n",
        "gloveEmbs.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhubJidu5tpz"
      },
      "outputs": [],
      "source": [
        "def embeddingOutput(X):\n",
        "    \"\"\"\n",
        "    X: input matrix\n",
        "    \"\"\"\n",
        "    maxLen = 10\n",
        "    embDim = 200\n",
        "    embOutput = np.zeros((len(X), maxLen, embDim))\n",
        "    for i in range(len(X)):\n",
        "        X[i] = X[i].split()\n",
        "        for j in range(maxLen):\n",
        "            try:\n",
        "                embOutput[i][j] = embeddings[X[i][j].lower()]\n",
        "            except:\n",
        "                embOutput[i][j] = np.zeros((embDim, ))\n",
        "    return embOutput"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AA2Z_ij_50xy"
      },
      "outputs": [],
      "source": [
        "embeddingMatrixTrain = embeddingOutput(trainData)\n",
        "embeddingMatrixTest = embeddingOutput(testData)\n",
        "embeddingMatrixVal = embeddingOutput(validData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SyL5rqm58bR",
        "outputId": "44df9b70-0466-4a24-a401-7f1b80c8be3c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((69992, 10, 200), (20000, 10, 200), (10008, 10, 200))"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embeddingMatrixTrain.shape, embeddingMatrixTest.shape, embeddingMatrixVal.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Obyp1DoC7kU_"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing import sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOinzfSZ70OZ"
      },
      "outputs": [],
      "source": [
        "trainData1 = trainData.copy()\n",
        "testData1 = testData.copy()\n",
        "validData1 = validData.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2pzJPN170Cg"
      },
      "outputs": [],
      "source": [
        "trainData1 = trainData1[1:]\n",
        "testData1 = testData1[1:]\n",
        "validData1 = validData1[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0nWjiq77zha"
      },
      "outputs": [],
      "source": [
        "wordFreq = {}\n",
        "for i in trainData:\n",
        "    # words = i.split()\n",
        "    for word in i:\n",
        "        if word in wordFreq:\n",
        "            wordFreq[word] += 1\n",
        "        else:\n",
        "            wordFreq[word] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yL5k_MDS8RmQ",
        "outputId": "387a31b0-6b43-4df8-81bc-69221ce4706c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "44842"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(wordFreq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3UVv0hw8RZr"
      },
      "outputs": [],
      "source": [
        "sortedWordFreq = dict(sorted(wordFreq.items(), reverse=True, key=lambda item: item[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHn533N-8RNG",
        "outputId": "c559e325-46a0-46c4-a1df-199f3a9f83ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44842\n"
          ]
        }
      ],
      "source": [
        "ctr = 0\n",
        "idx = 1\n",
        "idxToWord = {}\n",
        "wordToIdx = {}\n",
        "for i in sortedWordFreq:\n",
        "    # print(i, sortedWordFreq[i])\n",
        "    ctr += 1\n",
        "    # if sortedWordFreq[i] == 1:\n",
        "        # break\n",
        "    idxToWord[idx] = i\n",
        "    wordToIdx[i] = idx\n",
        "    idx += 1\n",
        "print(ctr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUZrhD1W8RCn",
        "outputId": "8b26cb18-805a-4253-a913-a875acd8eaea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "idxToWord[100]\n",
        "wordToIdx['wait']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9t47hOi8Q0z",
        "outputId": "d3168136-e317-4781-d926-794e2a554768"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 69992/69992 [00:55<00:00, 1254.48it/s]\n",
            "100%|██████████| 20000/20000 [00:00<00:00, 188288.87it/s]\n",
            "100%|██████████| 10008/10008 [00:00<00:00, 188887.21it/s]\n"
          ]
        }
      ],
      "source": [
        "for i in tqdm(range(len(trainData1))):\n",
        "    words = trainData1[i]\n",
        "    trainData1[i] = [wordToIdx[word] for word in words if word in wordToIdx.keys()]\n",
        "for i in tqdm(range(len(testData1))):\n",
        "    words = testData1[i]\n",
        "    testData1[i] = [wordToIdx[word] for word in words if word in wordToIdx.keys()]\n",
        "for i in tqdm(range(len(validData1))):\n",
        "    words = validData1[i]\n",
        "    validData1[i] = [wordToIdx[word] for word in words if word in wordToIdx.keys()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgDAEYUj8QmH",
        "outputId": "eba38387-8661-47b2-8f46-63ece06b5bee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "min len:  1\n",
            "max len:  20\n",
            "avg len:  6.980526345868099\n",
            "med len:  7.0\n",
            "vocab:  44842\n"
          ]
        }
      ],
      "source": [
        "sentLen = []\n",
        "vocab = set()\n",
        "for i in trainData:\n",
        "    sentLen.append(len(i))\n",
        "    for word in i:\n",
        "        vocab.add(word)\n",
        "print('min len: ', min(sentLen))\n",
        "print('max len: ', max(sentLen))\n",
        "print('avg len: ', np.mean(sentLen))\n",
        "print('med len: ', np.median(sentLen))\n",
        "print('vocab: ', len(vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OIo3iqU8w84"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing import sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBcxNfVF8wwW"
      },
      "outputs": [],
      "source": [
        "X_train = sequence.pad_sequences(trainData1, maxlen=10)\n",
        "X_test = sequence.pad_sequences(testData1, maxlen=10)\n",
        "X_val = sequence.pad_sequences(validData1, maxlen=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e830gf0u85C4"
      },
      "outputs": [],
      "source": [
        "from keras.utils import np_utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Lw5gQ9P9Cdr"
      },
      "outputs": [],
      "source": [
        "trainLabels = np_utils.to_categorical(trainLabels, 20)\n",
        "testLabels = np_utils.to_categorical(testLabels, 20)\n",
        "validLabels = np_utils.to_categorical(validLabels, 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BETxZxH9L-a",
        "outputId": "842b2fca-f7bc-43c7-8f77-ea030b3a22ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((69992, 20), (20000, 20), (10008, 20))"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainLabels.shape, testLabels.shape, validLabels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uF8tqxaK9RmT"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, RNN, Dense, Dropout, Embedding, RNN, Bidirectional, Add, merge, concatenate\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZCeY55B9TKK",
        "outputId": "56ea26f1-ebb6-44df-f436-d30be0987bae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 64)                67840     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 20)                1300      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 69,140\n",
            "Trainable params: 69,140\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "545/547 [============================>.] - ETA: 0s - loss: 2.5629 - accuracy: 0.2664\n",
            "Epoch 00001: val_loss improved from inf to 2.41182, saving model to lstmBestLoss.h5\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.29986, saving model to lsmtBestLoss.h5\n",
            "547/547 [==============================] - 16s 25ms/step - loss: 2.5626 - accuracy: 0.2664 - val_loss: 2.4118 - val_accuracy: 0.2999\n",
            "Epoch 2/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.4182 - accuracy: 0.3023\n",
            "Epoch 00002: val_loss improved from 2.41182 to 2.37631, saving model to lstmBestLoss.h5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.29986 to 0.30416, saving model to lsmtBestLoss.h5\n",
            "547/547 [==============================] - 13s 24ms/step - loss: 2.4180 - accuracy: 0.3023 - val_loss: 2.3763 - val_accuracy: 0.3042\n",
            "Epoch 3/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.3746 - accuracy: 0.3113\n",
            "Epoch 00003: val_loss improved from 2.37631 to 2.35817, saving model to lstmBestLoss.h5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.30416 to 0.31045, saving model to lsmtBestLoss.h5\n",
            "547/547 [==============================] - 13s 24ms/step - loss: 2.3749 - accuracy: 0.3112 - val_loss: 2.3582 - val_accuracy: 0.3105\n",
            "Epoch 4/50\n",
            "545/547 [============================>.] - ETA: 0s - loss: 2.3484 - accuracy: 0.3170\n",
            "Epoch 00004: val_loss improved from 2.35817 to 2.34639, saving model to lstmBestLoss.h5\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.31045 to 0.31275, saving model to lsmtBestLoss.h5\n",
            "547/547 [==============================] - 13s 24ms/step - loss: 2.3481 - accuracy: 0.3171 - val_loss: 2.3464 - val_accuracy: 0.3127\n",
            "Epoch 5/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.3269 - accuracy: 0.3212\n",
            "Epoch 00005: val_loss improved from 2.34639 to 2.34150, saving model to lstmBestLoss.h5\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.31275 to 0.31325, saving model to lsmtBestLoss.h5\n",
            "547/547 [==============================] - 13s 24ms/step - loss: 2.3270 - accuracy: 0.3212 - val_loss: 2.3415 - val_accuracy: 0.3132\n",
            "Epoch 6/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.3070 - accuracy: 0.3256\n",
            "Epoch 00006: val_loss improved from 2.34150 to 2.33739, saving model to lstmBestLoss.h5\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.31325 to 0.31505, saving model to lsmtBestLoss.h5\n",
            "547/547 [==============================] - 13s 25ms/step - loss: 2.3070 - accuracy: 0.3256 - val_loss: 2.3374 - val_accuracy: 0.3150\n",
            "Epoch 7/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.2879 - accuracy: 0.3306\n",
            "Epoch 00007: val_loss improved from 2.33739 to 2.33100, saving model to lstmBestLoss.h5\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.31505 to 0.31705, saving model to lsmtBestLoss.h5\n",
            "547/547 [==============================] - 13s 25ms/step - loss: 2.2875 - accuracy: 0.3307 - val_loss: 2.3310 - val_accuracy: 0.3170\n",
            "Epoch 8/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.2687 - accuracy: 0.3340\n",
            "Epoch 00008: val_loss did not improve from 2.33100\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.31705\n",
            "547/547 [==============================] - 13s 24ms/step - loss: 2.2685 - accuracy: 0.3342 - val_loss: 2.3383 - val_accuracy: 0.3153\n",
            "Epoch 9/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.2515 - accuracy: 0.3379\n",
            "Epoch 00009: val_loss did not improve from 2.33100\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.31705\n",
            "547/547 [==============================] - 13s 25ms/step - loss: 2.2516 - accuracy: 0.3378 - val_loss: 2.3359 - val_accuracy: 0.3169\n",
            "Epoch 10/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.2345 - accuracy: 0.3421\n",
            "Epoch 00010: val_loss did not improve from 2.33100\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.31705\n",
            "547/547 [==============================] - 13s 24ms/step - loss: 2.2345 - accuracy: 0.3421 - val_loss: 2.3472 - val_accuracy: 0.3144\n",
            "Epoch 11/50\n",
            "545/547 [============================>.] - ETA: 0s - loss: 2.2156 - accuracy: 0.3468\n",
            "Epoch 00011: val_loss did not improve from 2.33100\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.31705\n",
            "547/547 [==============================] - 13s 24ms/step - loss: 2.2160 - accuracy: 0.3467 - val_loss: 2.3480 - val_accuracy: 0.3130\n",
            "Epoch 12/50\n",
            "545/547 [============================>.] - ETA: 0s - loss: 2.1997 - accuracy: 0.3518\n",
            "Epoch 00012: val_loss did not improve from 2.33100\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.31705\n",
            "547/547 [==============================] - 13s 24ms/step - loss: 2.1995 - accuracy: 0.3519 - val_loss: 2.3580 - val_accuracy: 0.3165\n",
            "Epoch 13/50\n",
            "545/547 [============================>.] - ETA: 0s - loss: 2.1836 - accuracy: 0.3547\n",
            "Epoch 00013: val_loss did not improve from 2.33100\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.31705\n",
            "547/547 [==============================] - 13s 24ms/step - loss: 2.1833 - accuracy: 0.3546 - val_loss: 2.3590 - val_accuracy: 0.3142\n",
            "Epoch 14/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.1687 - accuracy: 0.3593\n",
            "Epoch 00014: val_loss did not improve from 2.33100\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.31705\n",
            "547/547 [==============================] - 13s 24ms/step - loss: 2.1689 - accuracy: 0.3593 - val_loss: 2.3637 - val_accuracy: 0.3117\n",
            "Epoch 15/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.1515 - accuracy: 0.3627\n",
            "Epoch 00015: val_loss did not improve from 2.33100\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.31705\n",
            "547/547 [==============================] - 13s 24ms/step - loss: 2.1512 - accuracy: 0.3628 - val_loss: 2.3735 - val_accuracy: 0.3137\n",
            "Epoch 16/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.1352 - accuracy: 0.3687\n",
            "Epoch 00016: val_loss did not improve from 2.33100\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.31705\n",
            "547/547 [==============================] - 13s 24ms/step - loss: 2.1352 - accuracy: 0.3687 - val_loss: 2.3857 - val_accuracy: 0.3131\n",
            "Epoch 17/50\n",
            "545/547 [============================>.] - ETA: 0s - loss: 2.1192 - accuracy: 0.3724\n",
            "Epoch 00017: val_loss did not improve from 2.33100\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.31705\n",
            "547/547 [==============================] - 13s 24ms/step - loss: 2.1195 - accuracy: 0.3723 - val_loss: 2.4043 - val_accuracy: 0.3094\n",
            "Epoch 00017: early stopping\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(64, input_shape=(10, 200))) #hidden state has 64 dims\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(20, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "checkPointLoss = ModelCheckpoint('lstmBestLoss.h5', monitor='val_loss', verbose=True, save_best_only=True)\n",
        "checkPointAcc = ModelCheckpoint('lsmtBestAcc.h5', monitor='val_accuracy', verbose=True, save_best_only=True)\n",
        "earlyStopping = EarlyStopping(monitor='val_accuracy', patience=10, verbose=True)\n",
        "hist = model.fit(embeddingMatrixTrain, trainLabels, epochs=50, batch_size=128,\n",
        "                 validation_data=(embeddingMatrixVal, validLabels), shuffle=True, callbacks=[checkPointLoss, checkPointAcc, earlyStopping])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 947
        },
        "id": "SR8MRd6cuf5K",
        "outputId": "b6a7a787-9063-4e4e-f3e4-79e0e7a04a38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 4s 5ms/step - loss: 2.3855 - accuracy: 0.3110\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 2.3238 - accuracy: 0.3178\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-27-8ba6d2b5b697>\", line 4, in <module>\n",
            "    model.load_weights('lstmBestAcc.h5')\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\", line 427, in __init__\n",
            "    swmr=swmr)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\", line 190, in make_fid\n",
            "    fid = h5f.open(name, flags, fapl=fapl)\n",
            "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
            "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
            "  File \"h5py/h5f.pyx\", line 96, in h5py.h5f.open\n",
            "OSError: Unable to open file (unable to open file: name = 'lstmBestAcc.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'OSError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 725, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 709, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.7/posixpath.py\", line 383, in abspath\n",
            "    cwd = os.getcwd()\n",
            "FileNotFoundError: [Errno 2] No such file or directory\n"
          ]
        },
        {
          "ename": "OSError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ],
      "source": [
        "model.evaluate(embeddingMatrixTest, testLabels)\n",
        "model.load_weights('lstmBestLoss.h5')\n",
        "model.evaluate(embeddingMatrixTest, testLabels)\n",
        "model.load_weights('lstmBestAcc.h5')\n",
        "model.evaluate(embeddingMatrixTest, testLabels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgxS8yPGvMNQ",
        "outputId": "c6b5654b-9df7-48e3-d36b-aae06ea5d40a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 100)               120400    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 100)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 50)                5050      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 50)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 20)                1020      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 126,470\n",
            "Trainable params: 126,470\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.5954 - accuracy: 0.2596\n",
            "Epoch 00001: val_loss improved from inf to 2.45077, saving model to lstmBestLoss.h5\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.29406, saving model to lsmtBestAcc.h5\n",
            "547/547 [==============================] - 12s 12ms/step - loss: 2.5954 - accuracy: 0.2596 - val_loss: 2.4508 - val_accuracy: 0.2941\n",
            "Epoch 2/50\n",
            "542/547 [============================>.] - ETA: 0s - loss: 2.4475 - accuracy: 0.2954\n",
            "Epoch 00002: val_loss improved from 2.45077 to 2.39758, saving model to lstmBestLoss.h5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.29406 to 0.30536, saving model to lsmtBestAcc.h5\n",
            "547/547 [==============================] - 5s 9ms/step - loss: 2.4471 - accuracy: 0.2953 - val_loss: 2.3976 - val_accuracy: 0.3054\n",
            "Epoch 3/50\n",
            "542/547 [============================>.] - ETA: 0s - loss: 2.4017 - accuracy: 0.3064\n",
            "Epoch 00003: val_loss improved from 2.39758 to 2.36902, saving model to lstmBestLoss.h5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.30536 to 0.30975, saving model to lsmtBestAcc.h5\n",
            "547/547 [==============================] - 5s 9ms/step - loss: 2.4018 - accuracy: 0.3063 - val_loss: 2.3690 - val_accuracy: 0.3098\n",
            "Epoch 4/50\n",
            "542/547 [============================>.] - ETA: 0s - loss: 2.3693 - accuracy: 0.3136\n",
            "Epoch 00004: val_loss improved from 2.36902 to 2.36495, saving model to lstmBestLoss.h5\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.30975 to 0.31055, saving model to lsmtBestAcc.h5\n",
            "547/547 [==============================] - 5s 10ms/step - loss: 2.3694 - accuracy: 0.3136 - val_loss: 2.3649 - val_accuracy: 0.3106\n",
            "Epoch 5/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.3460 - accuracy: 0.3182\n",
            "Epoch 00005: val_loss improved from 2.36495 to 2.35261, saving model to lstmBestLoss.h5\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.31055 to 0.31465, saving model to lsmtBestAcc.h5\n",
            "547/547 [==============================] - 5s 9ms/step - loss: 2.3459 - accuracy: 0.3183 - val_loss: 2.3526 - val_accuracy: 0.3146\n",
            "Epoch 6/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.3214 - accuracy: 0.3246\n",
            "Epoch 00006: val_loss improved from 2.35261 to 2.34425, saving model to lstmBestLoss.h5\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.31465 to 0.31715, saving model to lsmtBestAcc.h5\n",
            "547/547 [==============================] - 5s 10ms/step - loss: 2.3214 - accuracy: 0.3246 - val_loss: 2.3442 - val_accuracy: 0.3171\n",
            "Epoch 7/50\n",
            "543/547 [============================>.] - ETA: 0s - loss: 2.2965 - accuracy: 0.3304\n",
            "Epoch 00007: val_loss improved from 2.34425 to 2.34416, saving model to lstmBestLoss.h5\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.31715\n",
            "547/547 [==============================] - 5s 10ms/step - loss: 2.2968 - accuracy: 0.3302 - val_loss: 2.3442 - val_accuracy: 0.3168\n",
            "Epoch 8/50\n",
            "543/547 [============================>.] - ETA: 0s - loss: 2.2750 - accuracy: 0.3348\n",
            "Epoch 00008: val_loss improved from 2.34416 to 2.34358, saving model to lstmBestLoss.h5\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.31715\n",
            "547/547 [==============================] - 5s 9ms/step - loss: 2.2748 - accuracy: 0.3348 - val_loss: 2.3436 - val_accuracy: 0.3162\n",
            "Epoch 9/50\n",
            "545/547 [============================>.] - ETA: 0s - loss: 2.2514 - accuracy: 0.3420\n",
            "Epoch 00009: val_loss did not improve from 2.34358\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.31715\n",
            "547/547 [==============================] - 5s 9ms/step - loss: 2.2517 - accuracy: 0.3418 - val_loss: 2.3492 - val_accuracy: 0.3148\n",
            "Epoch 10/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.2242 - accuracy: 0.3486\n",
            "Epoch 00010: val_loss did not improve from 2.34358\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.31715\n",
            "547/547 [==============================] - 5s 10ms/step - loss: 2.2242 - accuracy: 0.3486 - val_loss: 2.3601 - val_accuracy: 0.3114\n",
            "Epoch 11/50\n",
            "543/547 [============================>.] - ETA: 0s - loss: 2.2022 - accuracy: 0.3531\n",
            "Epoch 00011: val_loss did not improve from 2.34358\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.31715\n",
            "547/547 [==============================] - 5s 9ms/step - loss: 2.2025 - accuracy: 0.3528 - val_loss: 2.3661 - val_accuracy: 0.3135\n",
            "Epoch 12/50\n",
            "543/547 [============================>.] - ETA: 0s - loss: 2.1767 - accuracy: 0.3596\n",
            "Epoch 00012: val_loss did not improve from 2.34358\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.31715\n",
            "547/547 [==============================] - 5s 9ms/step - loss: 2.1766 - accuracy: 0.3596 - val_loss: 2.3938 - val_accuracy: 0.3125\n",
            "Epoch 13/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.1491 - accuracy: 0.3670\n",
            "Epoch 00013: val_loss did not improve from 2.34358\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.31715\n",
            "547/547 [==============================] - 5s 9ms/step - loss: 2.1492 - accuracy: 0.3669 - val_loss: 2.4056 - val_accuracy: 0.3056\n",
            "Epoch 14/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.1246 - accuracy: 0.3727\n",
            "Epoch 00014: val_loss did not improve from 2.34358\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.31715\n",
            "547/547 [==============================] - 5s 10ms/step - loss: 2.1246 - accuracy: 0.3727 - val_loss: 2.4054 - val_accuracy: 0.3059\n",
            "Epoch 15/50\n",
            "544/547 [============================>.] - ETA: 0s - loss: 2.0957 - accuracy: 0.3805\n",
            "Epoch 00015: val_loss did not improve from 2.34358\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.31715\n",
            "547/547 [==============================] - 5s 10ms/step - loss: 2.0958 - accuracy: 0.3805 - val_loss: 2.4429 - val_accuracy: 0.3036\n",
            "Epoch 16/50\n",
            "542/547 [============================>.] - ETA: 0s - loss: 2.0678 - accuracy: 0.3860\n",
            "Epoch 00016: val_loss did not improve from 2.34358\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.31715\n",
            "547/547 [==============================] - 5s 9ms/step - loss: 2.0682 - accuracy: 0.3860 - val_loss: 2.4485 - val_accuracy: 0.3027\n",
            "Epoch 00016: early stopping\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(100, input_shape=(10, 200))) #hidden state has 64 dims\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(20, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "checkPointLoss = ModelCheckpoint('lstmBestLoss.h5', monitor='val_loss', verbose=True, save_best_only=True)\n",
        "checkPointAcc = ModelCheckpoint('lsmtBestAcc.h5', monitor='val_accuracy', verbose=True, save_best_only=True)\n",
        "earlyStopping = EarlyStopping(monitor='val_accuracy', patience=10, verbose=True)\n",
        "hist = model.fit(embeddingMatrixTrain, trainLabels, epochs=50, batch_size=128,\n",
        "                 validation_data=(embeddingMatrixVal, validLabels), shuffle=True, callbacks=[checkPointLoss, checkPointAcc, earlyStopping])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQwOVKwMwHQj",
        "outputId": "727190f6-8705-4409-80eb-164e5e618b39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 3s 5ms/step - loss: 2.3325 - accuracy: 0.3181\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 2.3317 - accuracy: 0.3194\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 2.3325 - accuracy: 0.3181\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[2.332508087158203, 0.3181000053882599]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(embeddingMatrixTest, testLabels)\n",
        "model.load_weights('lstmBestLoss.h5')\n",
        "model.evaluate(embeddingMatrixTest, testLabels)\n",
        "model.load_weights('lsmtBestAcc.h5')\n",
        "model.evaluate(embeddingMatrixTest, testLabels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OP1NK_lGdLI"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9QWt36_GpLW"
      },
      "outputs": [],
      "source": [
        "plt.style.use('seaborn')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "xunLl5qKGosX",
        "outputId": "f1f604cc-88e8-4540-c856-3ad0e70eb49f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(hist.history['accuracy'], label='train accuracy', c='red')\n",
        "plt.plot(hist.history['val_accuracy'], label='validation accuracy')\n",
        "plt.xlabel('Accuracy')\n",
        "plt.ylabel('Epochs')\n",
        "plt.legend()\n",
        "plt.title('Accuracy vs Epochs for LSTM model')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "CMyuHa8DGohM",
        "outputId": "6c7c46c7-b3ac-4938-8774-cb44b35cd18f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(hist.history['loss'], label='train loss', c='red')\n",
        "plt.plot(hist.history['val_loss'], label='validation loss')\n",
        "plt.xlabel('Loss')\n",
        "plt.ylabel('Epochs')\n",
        "plt.legend()\n",
        "plt.title('Loss vs Epochs for LSTM model')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJh7fABpGoXe"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qg8my7xEGoNI",
        "outputId": "38058dca-2efe-491b-9c2c-3e37be5d0a3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.80      0.43      4312\n",
            "           1       0.26      0.11      0.16      2022\n",
            "           2       0.33      0.51      0.40      1955\n",
            "           3       0.00      0.00      0.00      1099\n",
            "           4       0.39      0.44      0.41      1246\n",
            "           5       0.00      0.00      0.00       786\n",
            "           6       0.15      0.01      0.02       809\n",
            "           7       0.31      0.16      0.21       928\n",
            "           8       0.00      0.00      0.00       669\n",
            "           9       0.00      0.00      0.00       569\n",
            "          10       0.00      0.00      0.00       595\n",
            "          11       0.46      0.40      0.43       696\n",
            "          12       0.30      0.47      0.37       546\n",
            "          13       0.00      0.00      0.00       492\n",
            "          14       0.00      0.00      0.00       536\n",
            "          15       0.27      0.04      0.07       498\n",
            "          16       0.00      0.00      0.00       492\n",
            "          17       0.61      0.67      0.64       565\n",
            "          18       0.21      0.09      0.12       740\n",
            "          19       0.00      0.00      0.00       445\n",
            "\n",
            "    accuracy                           0.32     20000\n",
            "   macro avg       0.18      0.18      0.16     20000\n",
            "weighted avg       0.22      0.32      0.23     20000\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "preds = model.predict(embeddingMatrixTest)\n",
        "preds = np.argmax(preds, axis=1)\n",
        "finalLabels = np.argmax(testLabels, axis=1)\n",
        "cr = classification_report(finalLabels, preds)\n",
        "print(cr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xz7n_AYiGn9k",
        "outputId": "1559e8df-3b87-434a-826f-3177338cc267"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.81      0.43      2156\n",
            "           1       0.27      0.10      0.15      1011\n",
            "           2       0.33      0.49      0.40       978\n",
            "           3       0.00      0.00      0.00       549\n",
            "           4       0.37      0.43      0.40       624\n",
            "           5       0.00      0.00      0.00       393\n",
            "           6       0.15      0.01      0.02       405\n",
            "           7       0.33      0.17      0.23       465\n",
            "           8       0.00      0.00      0.00       335\n",
            "           9       0.00      0.00      0.00       285\n",
            "          10       0.00      0.00      0.00       298\n",
            "          11       0.46      0.40      0.43       348\n",
            "          12       0.30      0.44      0.36       273\n",
            "          13       0.00      0.00      0.00       246\n",
            "          14       0.00      0.00      0.00       269\n",
            "          15       0.14      0.02      0.04       250\n",
            "          16       0.00      0.00      0.00       246\n",
            "          17       0.61      0.70      0.65       283\n",
            "          18       0.20      0.08      0.11       371\n",
            "          19       0.00      0.00      0.00       223\n",
            "\n",
            "    accuracy                           0.32     10008\n",
            "   macro avg       0.17      0.18      0.16     10008\n",
            "weighted avg       0.22      0.32      0.23     10008\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "preds = model.predict(embeddingMatrixVal)\n",
        "preds = np.argmax(preds, axis=1)\n",
        "finalLabels = np.argmax(validLabels, axis=1)\n",
        "cr = classification_report(finalLabels, preds)\n",
        "print(cr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqolbpQFJvgR",
        "outputId": "c040dbe8-8146-48cc-d4df-cd48ae1590e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.82      0.44     15090\n",
            "           1       0.35      0.14      0.20      7076\n",
            "           2       0.37      0.56      0.44      6842\n",
            "           3       0.00      0.00      0.00      3842\n",
            "           4       0.44      0.50      0.47      4363\n",
            "           5       0.00      0.00      0.00      2751\n",
            "           6       0.24      0.02      0.03      2831\n",
            "           7       0.40      0.21      0.27      3250\n",
            "           8       0.00      0.00      0.00      2341\n",
            "           9       0.00      0.00      0.00      1992\n",
            "          10       0.00      0.00      0.00      2083\n",
            "          11       0.55      0.49      0.52      2433\n",
            "          12       0.35      0.51      0.41      1908\n",
            "          13       0.00      0.00      0.00      1722\n",
            "          14       1.00      0.00      0.00      1878\n",
            "          15       0.36      0.07      0.11      1745\n",
            "          16       0.00      0.00      0.00      1721\n",
            "          17       0.61      0.70      0.65      1976\n",
            "          18       0.31      0.13      0.18      2592\n",
            "          19       0.00      0.00      0.00      1556\n",
            "\n",
            "    accuracy                           0.34     69992\n",
            "   macro avg       0.26      0.21      0.19     69992\n",
            "weighted avg       0.28      0.34      0.26     69992\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "preds = model.predict(embeddingMatrixTrain)\n",
        "preds = np.argmax(preds, axis=1)\n",
        "finalLabels = np.argmax(trainLabels, axis=1)\n",
        "cr = classification_report(finalLabels, preds)\n",
        "print(cr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJDTpkJPHqFv",
        "outputId": "4f45248a-64b3-4347-e2cf-fd35bbe6b8e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_4 (LSTM)               (None, 10, 100)           120400    \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 10, 100)           0         \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 10, 100)           80400     \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 10, 100)           0         \n",
            "                                                                 \n",
            " lstm_6 (LSTM)               (None, 100)               80400     \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 50)                5050      \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 50)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 20)                1020      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 287,270\n",
            "Trainable params: 287,270\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.5855 - accuracy: 0.2640\n",
            "Epoch 00001: val_loss improved from inf to 2.43373, saving model to lstmBestLoss.h5\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.29566, saving model to lsmtBestAcc.h5\n",
            "547/547 [==============================] - 19s 24ms/step - loss: 2.5853 - accuracy: 0.2640 - val_loss: 2.4337 - val_accuracy: 0.2957\n",
            "Epoch 2/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.4471 - accuracy: 0.2979\n",
            "Epoch 00002: val_loss improved from 2.43373 to 2.39306, saving model to lstmBestLoss.h5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.29566 to 0.30685, saving model to lsmtBestAcc.h5\n",
            "547/547 [==============================] - 12s 22ms/step - loss: 2.4471 - accuracy: 0.2979 - val_loss: 2.3931 - val_accuracy: 0.3069\n",
            "Epoch 3/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.4067 - accuracy: 0.3056\n",
            "Epoch 00003: val_loss improved from 2.39306 to 2.36566, saving model to lstmBestLoss.h5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.30685 to 0.31445, saving model to lsmtBestAcc.h5\n",
            "547/547 [==============================] - 12s 22ms/step - loss: 2.4067 - accuracy: 0.3056 - val_loss: 2.3657 - val_accuracy: 0.3144\n",
            "Epoch 4/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.3741 - accuracy: 0.3155\n",
            "Epoch 00004: val_loss improved from 2.36566 to 2.35938, saving model to lstmBestLoss.h5\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.31445\n",
            "547/547 [==============================] - 12s 21ms/step - loss: 2.3739 - accuracy: 0.3156 - val_loss: 2.3594 - val_accuracy: 0.3133\n",
            "Epoch 5/50\n",
            "545/547 [============================>.] - ETA: 0s - loss: 2.3513 - accuracy: 0.3221\n",
            "Epoch 00005: val_loss improved from 2.35938 to 2.35820, saving model to lstmBestLoss.h5\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.31445 to 0.31625, saving model to lsmtBestAcc.h5\n",
            "547/547 [==============================] - 12s 22ms/step - loss: 2.3514 - accuracy: 0.3222 - val_loss: 2.3582 - val_accuracy: 0.3162\n",
            "Epoch 6/50\n",
            "545/547 [============================>.] - ETA: 0s - loss: 2.3265 - accuracy: 0.3258\n",
            "Epoch 00006: val_loss improved from 2.35820 to 2.35464, saving model to lstmBestLoss.h5\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.31625 to 0.31635, saving model to lsmtBestAcc.h5\n",
            "547/547 [==============================] - 12s 22ms/step - loss: 2.3260 - accuracy: 0.3260 - val_loss: 2.3546 - val_accuracy: 0.3163\n",
            "Epoch 7/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.3013 - accuracy: 0.3322\n",
            "Epoch 00007: val_loss did not improve from 2.35464\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.31635\n",
            "547/547 [==============================] - 11s 21ms/step - loss: 2.3014 - accuracy: 0.3321 - val_loss: 2.3609 - val_accuracy: 0.3153\n",
            "Epoch 8/50\n",
            "545/547 [============================>.] - ETA: 0s - loss: 2.2760 - accuracy: 0.3384\n",
            "Epoch 00008: val_loss did not improve from 2.35464\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.31635\n",
            "547/547 [==============================] - 11s 21ms/step - loss: 2.2758 - accuracy: 0.3385 - val_loss: 2.3731 - val_accuracy: 0.3154\n",
            "Epoch 9/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.2527 - accuracy: 0.3452\n",
            "Epoch 00009: val_loss did not improve from 2.35464\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.31635\n",
            "547/547 [==============================] - 11s 20ms/step - loss: 2.2527 - accuracy: 0.3452 - val_loss: 2.3677 - val_accuracy: 0.3145\n",
            "Epoch 10/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.2250 - accuracy: 0.3507\n",
            "Epoch 00010: val_loss did not improve from 2.35464\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.31635\n",
            "547/547 [==============================] - 11s 20ms/step - loss: 2.2250 - accuracy: 0.3507 - val_loss: 2.3758 - val_accuracy: 0.3100\n",
            "Epoch 11/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.1961 - accuracy: 0.3600\n",
            "Epoch 00011: val_loss did not improve from 2.35464\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.31635\n",
            "547/547 [==============================] - 11s 20ms/step - loss: 2.1961 - accuracy: 0.3600 - val_loss: 2.4005 - val_accuracy: 0.3088\n",
            "Epoch 12/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.1679 - accuracy: 0.3662\n",
            "Epoch 00012: val_loss did not improve from 2.35464\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.31635\n",
            "547/547 [==============================] - 11s 20ms/step - loss: 2.1679 - accuracy: 0.3662 - val_loss: 2.4135 - val_accuracy: 0.3060\n",
            "Epoch 13/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.1394 - accuracy: 0.3751\n",
            "Epoch 00013: val_loss did not improve from 2.35464\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.31635\n",
            "547/547 [==============================] - 11s 20ms/step - loss: 2.1394 - accuracy: 0.3750 - val_loss: 2.4242 - val_accuracy: 0.3052\n",
            "Epoch 14/50\n",
            "545/547 [============================>.] - ETA: 0s - loss: 2.1108 - accuracy: 0.3812\n",
            "Epoch 00014: val_loss did not improve from 2.35464\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.31635\n",
            "547/547 [==============================] - 11s 21ms/step - loss: 2.1107 - accuracy: 0.3812 - val_loss: 2.4718 - val_accuracy: 0.3058\n",
            "Epoch 15/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.0820 - accuracy: 0.3875\n",
            "Epoch 00015: val_loss did not improve from 2.35464\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.31635\n",
            "547/547 [==============================] - 11s 20ms/step - loss: 2.0820 - accuracy: 0.3875 - val_loss: 2.5049 - val_accuracy: 0.2972\n",
            "Epoch 16/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.0535 - accuracy: 0.3953\n",
            "Epoch 00016: val_loss did not improve from 2.35464\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.31635\n",
            "547/547 [==============================] - 11s 20ms/step - loss: 2.0535 - accuracy: 0.3953 - val_loss: 2.5085 - val_accuracy: 0.2990\n",
            "Epoch 00016: early stopping\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(100, input_shape=(10, 200), return_sequences=True)) #hidden state has 64 dims\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(20, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "checkPointLoss = ModelCheckpoint('lstmBestLoss.h5', monitor='val_loss', verbose=True, save_best_only=True)\n",
        "checkPointAcc = ModelCheckpoint('lsmtBestAcc.h5', monitor='val_accuracy', verbose=True, save_best_only=True)\n",
        "earlyStopping = EarlyStopping(monitor='val_accuracy', patience=10, verbose=True)\n",
        "hist = model.fit(embeddingMatrixTrain, trainLabels, epochs=50, batch_size=128,\n",
        "                 validation_data=(embeddingMatrixVal, validLabels), shuffle=True, callbacks=[checkPointLoss, checkPointAcc, earlyStopping])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5q_x7tUrHqO5",
        "outputId": "b17e7ffa-999e-47bd-f1e3-7a98c7a45bac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 4s 6ms/step - loss: 2.5117 - accuracy: 0.3041\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 2.3314 - accuracy: 0.3178\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 2.3314 - accuracy: 0.3178\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[2.3313639163970947, 0.3178499937057495]"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(embeddingMatrixTest, testLabels)\n",
        "model.load_weights('lstmBestLoss.h5')\n",
        "model.evaluate(embeddingMatrixTest, testLabels)\n",
        "model.load_weights('lsmtBestAcc.h5')\n",
        "model.evaluate(embeddingMatrixTest, testLabels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H082GMMk7HzO"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(44843, 200, trainable=True))\n",
        "model.add(LSTM(100)) #hidden state has 64 dims\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(20, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "checkPointLoss = ModelCheckpoint('lstmBestLoss.h5', monitor='val_loss', verbose=True, save_best_only=True)\n",
        "checkPointAcc = ModelCheckpoint('lsmtBestAcc.h5', monitor='val_accuracy', verbose=True, save_best_only=True)\n",
        "earlyStopping = EarlyStopping(monitor='val_accuracy', patience=10, verbose=True)\n",
        "hist = model.fit(embeddingMatrixTrain, trainLabels, epochs=50, batch_size=128,\n",
        "                 validation_data=(embeddingMatrixVal, validLabels), shuffle=True, callbacks=[checkPointLoss, checkPointAcc, earlyStopping])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-MbJQ8WcxjD4",
        "outputId": "8a24eb77-3f1c-4da8-bff3-94db99420219"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_2 (LSTM)               (None, 10, 100)           120400    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 10, 100)           0         \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 10, 100)           80400     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 10, 100)           0         \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 10, 100)           80400     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 10, 100)           0         \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 10, 100)           80400     \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 10, 100)           0         \n",
            "                                                                 \n",
            " lstm_6 (LSTM)               (None, 10, 100)           80400     \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 10, 100)           0         \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (None, 10, 100)           80400     \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 10, 100)           0         \n",
            "                                                                 \n",
            " lstm_8 (LSTM)               (None, 100)               80400     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 50)                5050      \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 50)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 20)                1020      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 608,870\n",
            "Trainable params: 608,870\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.6785 - accuracy: 0.2298\n",
            "Epoch 00001: val_loss improved from inf to 2.55310, saving model to lstmBestLoss.h5\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.26309, saving model to lsmtBestAcc.h5\n",
            "547/547 [==============================] - 143s 237ms/step - loss: 2.6785 - accuracy: 0.2298 - val_loss: 2.5531 - val_accuracy: 0.2631\n",
            "Epoch 2/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.5241 - accuracy: 0.2780\n",
            "Epoch 00002: val_loss improved from 2.55310 to 2.46698, saving model to lstmBestLoss.h5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.26309 to 0.29107, saving model to lsmtBestAcc.h5\n",
            "547/547 [==============================] - 125s 229ms/step - loss: 2.5241 - accuracy: 0.2780 - val_loss: 2.4670 - val_accuracy: 0.2911\n",
            "Epoch 3/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.4652 - accuracy: 0.2943\n",
            "Epoch 00003: val_loss improved from 2.46698 to 2.43671, saving model to lstmBestLoss.h5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.29107 to 0.30086, saving model to lsmtBestAcc.h5\n",
            "547/547 [==============================] - 126s 230ms/step - loss: 2.4652 - accuracy: 0.2943 - val_loss: 2.4367 - val_accuracy: 0.3009\n",
            "Epoch 4/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.4345 - accuracy: 0.3023\n",
            "Epoch 00004: val_loss improved from 2.43671 to 2.41951, saving model to lstmBestLoss.h5\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.30086 to 0.30386, saving model to lsmtBestAcc.h5\n",
            "547/547 [==============================] - 124s 227ms/step - loss: 2.4345 - accuracy: 0.3023 - val_loss: 2.4195 - val_accuracy: 0.3039\n",
            "Epoch 5/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.4070 - accuracy: 0.3066\n",
            "Epoch 00005: val_loss improved from 2.41951 to 2.40884, saving model to lstmBestLoss.h5\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.30386\n",
            "547/547 [==============================] - 125s 229ms/step - loss: 2.4070 - accuracy: 0.3066 - val_loss: 2.4088 - val_accuracy: 0.3012\n",
            "Epoch 6/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.3817 - accuracy: 0.3124\n",
            "Epoch 00006: val_loss improved from 2.40884 to 2.40594, saving model to lstmBestLoss.h5\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.30386 to 0.30735, saving model to lsmtBestAcc.h5\n",
            "547/547 [==============================] - 124s 227ms/step - loss: 2.3817 - accuracy: 0.3124 - val_loss: 2.4059 - val_accuracy: 0.3074\n",
            "Epoch 7/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.3576 - accuracy: 0.3177\n",
            "Epoch 00007: val_loss improved from 2.40594 to 2.39076, saving model to lstmBestLoss.h5\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.30735 to 0.31005, saving model to lsmtBestAcc.h5\n",
            "547/547 [==============================] - 124s 227ms/step - loss: 2.3576 - accuracy: 0.3177 - val_loss: 2.3908 - val_accuracy: 0.3101\n",
            "Epoch 8/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.3297 - accuracy: 0.3254\n",
            "Epoch 00008: val_loss did not improve from 2.39076\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.31005 to 0.31225, saving model to lsmtBestAcc.h5\n",
            "547/547 [==============================] - 122s 223ms/step - loss: 2.3297 - accuracy: 0.3254 - val_loss: 2.3917 - val_accuracy: 0.3123\n",
            "Epoch 9/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.3083 - accuracy: 0.3299\n",
            "Epoch 00009: val_loss did not improve from 2.39076\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.31225\n",
            "547/547 [==============================] - 120s 220ms/step - loss: 2.3083 - accuracy: 0.3299 - val_loss: 2.4044 - val_accuracy: 0.3114\n",
            "Epoch 10/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.2816 - accuracy: 0.3377\n",
            "Epoch 00010: val_loss did not improve from 2.39076\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.31225\n",
            "547/547 [==============================] - 122s 223ms/step - loss: 2.2816 - accuracy: 0.3377 - val_loss: 2.4164 - val_accuracy: 0.3108\n",
            "Epoch 11/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.2600 - accuracy: 0.3431\n",
            "Epoch 00011: val_loss did not improve from 2.39076\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.31225\n",
            "547/547 [==============================] - 121s 222ms/step - loss: 2.2600 - accuracy: 0.3431 - val_loss: 2.4275 - val_accuracy: 0.3040\n",
            "Epoch 12/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.2332 - accuracy: 0.3489\n",
            "Epoch 00012: val_loss did not improve from 2.39076\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.31225\n",
            "547/547 [==============================] - 119s 218ms/step - loss: 2.2332 - accuracy: 0.3489 - val_loss: 2.4418 - val_accuracy: 0.3089\n",
            "Epoch 13/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.2114 - accuracy: 0.3555\n",
            "Epoch 00013: val_loss did not improve from 2.39076\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.31225\n",
            "547/547 [==============================] - 120s 219ms/step - loss: 2.2114 - accuracy: 0.3555 - val_loss: 2.4402 - val_accuracy: 0.3046\n",
            "Epoch 14/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.1891 - accuracy: 0.3612\n",
            "Epoch 00014: val_loss did not improve from 2.39076\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.31225\n",
            "547/547 [==============================] - 122s 222ms/step - loss: 2.1891 - accuracy: 0.3612 - val_loss: 2.4857 - val_accuracy: 0.3033\n",
            "Epoch 15/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.1655 - accuracy: 0.3666\n",
            "Epoch 00015: val_loss did not improve from 2.39076\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.31225\n",
            "547/547 [==============================] - 123s 224ms/step - loss: 2.1655 - accuracy: 0.3666 - val_loss: 2.4902 - val_accuracy: 0.2999\n",
            "Epoch 16/50\n",
            "275/547 [==============>...............] - ETA: 59s - loss: 2.1351 - accuracy: 0.3724"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-22104032914f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mearlyStopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m hist = model.fit(embeddingMatrixTrain, trainLabels, epochs=50, batch_size=128,\n\u001b[0;32m---> 24\u001b[0;31m                  validation_data=(embeddingMatrixVal, validLabels), shuffle=True, callbacks=[checkPointLoss, checkPointAcc, earlyStopping])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(100, input_shape=(10, 200), return_sequences=True)) #hidden state has 64 dims\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(100, return_sequences=True)) \n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(100, return_sequences=True)) \n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(100, return_sequences=True)) \n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(100, return_sequences=True)) \n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(100, return_sequences=True)) \n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(20, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "checkPointLoss = ModelCheckpoint('lstmBestLoss.h5', monitor='val_loss', verbose=True, save_best_only=True)\n",
        "checkPointAcc = ModelCheckpoint('lsmtBestAcc.h5', monitor='val_accuracy', verbose=True, save_best_only=True)\n",
        "earlyStopping = EarlyStopping(monitor='val_accuracy', patience=10, verbose=True)\n",
        "hist = model.fit(embeddingMatrixTrain, trainLabels, epochs=50, batch_size=128,\n",
        "                 validation_data=(embeddingMatrixVal, validLabels), shuffle=True, callbacks=[checkPointLoss, checkPointAcc, earlyStopping])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kD4zxTOxivL",
        "outputId": "6f1ef9ef-1f32-4c7a-b039-2d58e37320bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 17s 23ms/step - loss: 2.4830 - accuracy: 0.3018\n",
            "625/625 [==============================] - 14s 22ms/step - loss: 2.3859 - accuracy: 0.3137\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 2.3875 - accuracy: 0.3130\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[2.387470006942749, 0.31299999356269836]"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(embeddingMatrixTest, testLabels)\n",
        "model.load_weights('lstmBestLoss.h5')\n",
        "model.evaluate(embeddingMatrixTest, testLabels)\n",
        "model.load_weights('lsmtBestAcc.h5')\n",
        "model.evaluate(embeddingMatrixTest, testLabels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_dbwVabDTQl",
        "outputId": "c55e16b3-fc16-4744-96c7-05b26c2b76f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 3s 4ms/step - loss: 2.4386 - accuracy: 0.2979\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 2.3243 - accuracy: 0.3184\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[2.3243110179901123, 0.31839999556541443]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(embeddingMatrixTest, testLabels)\n",
        "model.load_weights('bestModel.h5')\n",
        "model.evaluate(embeddingMatrixTest, testLabels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrmQtAyJDiVl",
        "outputId": "9713f41e-690e-445d-e98a-366d7d47a08a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_3 (LSTM)               (None, 10, 64)            67840     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 10, 64)            0         \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 64)                33024     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 20)                1300      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 102,164\n",
            "Trainable params: 102,164\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.5550 - accuracy: 0.2703\n",
            "Epoch 00001: val_loss improved from inf to 2.40379, saving model to bestModel.h5\n",
            "547/547 [==============================] - 25s 40ms/step - loss: 2.5548 - accuracy: 0.2704 - val_loss: 2.4038 - val_accuracy: 0.3040\n",
            "Epoch 2/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.4190 - accuracy: 0.3047\n",
            "Epoch 00002: val_loss improved from 2.40379 to 2.37394, saving model to bestModel.h5\n",
            "547/547 [==============================] - 21s 39ms/step - loss: 2.4190 - accuracy: 0.3047 - val_loss: 2.3739 - val_accuracy: 0.3088\n",
            "Epoch 3/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.3741 - accuracy: 0.3127\n",
            "Epoch 00003: val_loss improved from 2.37394 to 2.34792, saving model to bestModel.h5\n",
            "547/547 [==============================] - 21s 39ms/step - loss: 2.3741 - accuracy: 0.3127 - val_loss: 2.3479 - val_accuracy: 0.3112\n",
            "Epoch 4/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.3490 - accuracy: 0.3192\n",
            "Epoch 00004: val_loss improved from 2.34792 to 2.34286, saving model to bestModel.h5\n",
            "547/547 [==============================] - 21s 38ms/step - loss: 2.3488 - accuracy: 0.3193 - val_loss: 2.3429 - val_accuracy: 0.3175\n",
            "Epoch 5/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.3251 - accuracy: 0.3250\n",
            "Epoch 00005: val_loss improved from 2.34286 to 2.33599, saving model to bestModel.h5\n",
            "547/547 [==============================] - 21s 39ms/step - loss: 2.3251 - accuracy: 0.3250 - val_loss: 2.3360 - val_accuracy: 0.3154\n",
            "Epoch 6/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.3031 - accuracy: 0.3304\n",
            "Epoch 00006: val_loss improved from 2.33599 to 2.33302, saving model to bestModel.h5\n",
            "547/547 [==============================] - 21s 39ms/step - loss: 2.3031 - accuracy: 0.3304 - val_loss: 2.3330 - val_accuracy: 0.3136\n",
            "Epoch 7/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.2833 - accuracy: 0.3339\n",
            "Epoch 00007: val_loss improved from 2.33302 to 2.33115, saving model to bestModel.h5\n",
            "547/547 [==============================] - 21s 39ms/step - loss: 2.2836 - accuracy: 0.3338 - val_loss: 2.3312 - val_accuracy: 0.3160\n",
            "Epoch 8/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.2615 - accuracy: 0.3386\n",
            "Epoch 00008: val_loss did not improve from 2.33115\n",
            "547/547 [==============================] - 21s 38ms/step - loss: 2.2616 - accuracy: 0.3386 - val_loss: 2.3359 - val_accuracy: 0.3159\n",
            "Epoch 9/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.2451 - accuracy: 0.3454\n",
            "Epoch 00009: val_loss did not improve from 2.33115\n",
            "547/547 [==============================] - 21s 38ms/step - loss: 2.2449 - accuracy: 0.3455 - val_loss: 2.3346 - val_accuracy: 0.3184\n",
            "Epoch 10/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.2267 - accuracy: 0.3477\n",
            "Epoch 00010: val_loss did not improve from 2.33115\n",
            "547/547 [==============================] - 21s 38ms/step - loss: 2.2267 - accuracy: 0.3477 - val_loss: 2.3397 - val_accuracy: 0.3131\n",
            "Epoch 11/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.2059 - accuracy: 0.3544\n",
            "Epoch 00011: val_loss did not improve from 2.33115\n",
            "547/547 [==============================] - 21s 38ms/step - loss: 2.2059 - accuracy: 0.3544 - val_loss: 2.3552 - val_accuracy: 0.3107\n",
            "Epoch 12/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.1870 - accuracy: 0.3571\n",
            "Epoch 00012: val_loss did not improve from 2.33115\n",
            "547/547 [==============================] - 21s 39ms/step - loss: 2.1870 - accuracy: 0.3571 - val_loss: 2.3663 - val_accuracy: 0.3075\n",
            "Epoch 13/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.1711 - accuracy: 0.3623\n",
            "Epoch 00013: val_loss did not improve from 2.33115\n",
            "547/547 [==============================] - 21s 38ms/step - loss: 2.1711 - accuracy: 0.3624 - val_loss: 2.3680 - val_accuracy: 0.3132\n",
            "Epoch 14/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.1536 - accuracy: 0.3681\n",
            "Epoch 00014: val_loss did not improve from 2.33115\n",
            "547/547 [==============================] - 21s 39ms/step - loss: 2.1536 - accuracy: 0.3681 - val_loss: 2.3822 - val_accuracy: 0.3093\n",
            "Epoch 15/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.1366 - accuracy: 0.3734\n",
            "Epoch 00015: val_loss did not improve from 2.33115\n",
            "547/547 [==============================] - 21s 39ms/step - loss: 2.1366 - accuracy: 0.3734 - val_loss: 2.4063 - val_accuracy: 0.3049\n",
            "Epoch 16/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.1184 - accuracy: 0.3785\n",
            "Epoch 00016: val_loss did not improve from 2.33115\n",
            "547/547 [==============================] - 21s 38ms/step - loss: 2.1184 - accuracy: 0.3785 - val_loss: 2.4053 - val_accuracy: 0.3062\n",
            "Epoch 17/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.1053 - accuracy: 0.3806\n",
            "Epoch 00017: val_loss did not improve from 2.33115\n",
            "547/547 [==============================] - 21s 38ms/step - loss: 2.1053 - accuracy: 0.3806 - val_loss: 2.4178 - val_accuracy: 0.3041\n",
            "Epoch 00017: early stopping\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(64, input_shape=(10, 200), return_sequences=True)) #hidden state has 64 dims\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(64)) #hidden state has 64 dims\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(20, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "checkPoint = ModelCheckpoint('bestModel.h5', monitor='val_loss', verbose=True, save_best_only=True)\n",
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=True)\n",
        "hist = model.fit(embeddingMatrixTrain, trainLabels, epochs=50, batch_size=128,\n",
        "                 validation_data=(embeddingMatrixVal, validLabels), shuffle=True, callbacks=[checkPoint, earlyStopping])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxEqmdeZ9hMK",
        "outputId": "4aa5a000-716e-4b7a-d164-025e555442bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, None, 200)         8968600   \n",
            "                                                                 \n",
            " lstm_12 (LSTM)              (None, 100)               120400    \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 100)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 50)                5050      \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 50)                0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 20)                1020      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,095,070\n",
            "Trainable params: 9,095,070\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.6438 - accuracy: 0.2473\n",
            "Epoch 00001: val_loss improved from inf to 2.46933, saving model to lstmBestLoss.h5\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.29057, saving model to lsmtBestAcc.h5\n",
            "547/547 [==============================] - 93s 166ms/step - loss: 2.6438 - accuracy: 0.2473 - val_loss: 2.4693 - val_accuracy: 0.2906\n",
            "Epoch 2/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.3442 - accuracy: 0.3222\n",
            "Epoch 00002: val_loss improved from 2.46933 to 2.44814, saving model to lstmBestLoss.h5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.29057 to 0.29766, saving model to lsmtBestAcc.h5\n",
            "547/547 [==============================] - 86s 156ms/step - loss: 2.3442 - accuracy: 0.3222 - val_loss: 2.4481 - val_accuracy: 0.2977\n",
            "Epoch 3/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.0734 - accuracy: 0.3878\n",
            "Epoch 00003: val_loss did not improve from 2.44814\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.29766\n",
            "547/547 [==============================] - 82s 151ms/step - loss: 2.0734 - accuracy: 0.3878 - val_loss: 2.5410 - val_accuracy: 0.2865\n",
            "Epoch 4/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 1.7957 - accuracy: 0.4689\n",
            "Epoch 00004: val_loss did not improve from 2.44814\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.29766\n",
            "547/547 [==============================] - 76s 140ms/step - loss: 1.7957 - accuracy: 0.4689 - val_loss: 2.7060 - val_accuracy: 0.2668\n",
            "Epoch 00004: early stopping\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(44843, 200, trainable=True))\n",
        "model.add(LSTM(100)) #hidden state has 64 dims\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(20, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "checkPointLoss = ModelCheckpoint('lstmBestLoss.h5', monitor='val_loss', verbose=True, save_best_only=True)\n",
        "checkPointAcc = ModelCheckpoint('lsmtBestAcc.h5', monitor='val_accuracy', verbose=True, save_best_only=True)\n",
        "earlyStopping = EarlyStopping(monitor='val_accuracy', patience=2, verbose=True)\n",
        "hist = model.fit(X_train, trainLabels, epochs=50, batch_size=128,\n",
        "                 validation_data=(X_val, validLabels), shuffle=True, callbacks=[checkPointLoss, checkPointAcc, earlyStopping])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUq4X2Q79hJD",
        "outputId": "451c7b3f-14fe-4ccd-ea7b-36adc170f4ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 5s 7ms/step - loss: 2.6909 - accuracy: 0.2670\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 2.4402 - accuracy: 0.2986\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 2.4402 - accuracy: 0.2986\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[2.4401957988739014, 0.2985999882221222]"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(X_test, testLabels)\n",
        "model.load_weights('lstmBestLoss.h5')\n",
        "model.evaluate(X_test, testLabels)\n",
        "model.load_weights('lsmtBestAcc.h5')\n",
        "model.evaluate(X_test, testLabels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLELeQZbEEz5",
        "outputId": "772d956f-3eaf-4763-adb6-e14360d9f177"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 5s 6ms/step - loss: 2.4079 - accuracy: 0.3094\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 2.3237 - accuracy: 0.3204\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[2.3236546516418457, 0.3203999996185303]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(embeddingMatrixTest, testLabels)\n",
        "model.load_weights('bestModel.h5')\n",
        "model.evaluate(embeddingMatrixTest, testLabels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qy0IVrhCFpSX",
        "outputId": "b6e3059f-08f9-443f-be8d-759838018cc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_7 (LSTM)               (None, 10, 128)           168448    \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 10, 128)           0         \n",
            "                                                                 \n",
            " lstm_8 (LSTM)               (None, 128)               131584    \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 20)                2580      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 302,612\n",
            "Trainable params: 302,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.4941 - accuracy: 0.2808\n",
            "Epoch 00001: val_loss improved from inf to 2.38838, saving model to bestModel.h5\n",
            "547/547 [==============================] - 54s 92ms/step - loss: 2.4941 - accuracy: 0.2808 - val_loss: 2.3884 - val_accuracy: 0.3057\n",
            "Epoch 2/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.3779 - accuracy: 0.3100\n",
            "Epoch 00002: val_loss improved from 2.38838 to 2.35267, saving model to bestModel.h5\n",
            "547/547 [==============================] - 50s 91ms/step - loss: 2.3779 - accuracy: 0.3100 - val_loss: 2.3527 - val_accuracy: 0.3112\n",
            "Epoch 3/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.3348 - accuracy: 0.3190\n",
            "Epoch 00003: val_loss improved from 2.35267 to 2.34639, saving model to bestModel.h5\n",
            "547/547 [==============================] - 50s 91ms/step - loss: 2.3348 - accuracy: 0.3190 - val_loss: 2.3464 - val_accuracy: 0.3091\n",
            "Epoch 4/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.3008 - accuracy: 0.3248\n",
            "Epoch 00004: val_loss improved from 2.34639 to 2.33248, saving model to bestModel.h5\n",
            "547/547 [==============================] - 50s 91ms/step - loss: 2.3008 - accuracy: 0.3248 - val_loss: 2.3325 - val_accuracy: 0.3157\n",
            "Epoch 5/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.2686 - accuracy: 0.3330\n",
            "Epoch 00005: val_loss improved from 2.33248 to 2.33107, saving model to bestModel.h5\n",
            "547/547 [==============================] - 50s 91ms/step - loss: 2.2686 - accuracy: 0.3330 - val_loss: 2.3311 - val_accuracy: 0.3125\n",
            "Epoch 6/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.2328 - accuracy: 0.3437\n",
            "Epoch 00006: val_loss improved from 2.33107 to 2.32213, saving model to bestModel.h5\n",
            "547/547 [==============================] - 50s 92ms/step - loss: 2.2328 - accuracy: 0.3437 - val_loss: 2.3221 - val_accuracy: 0.3176\n",
            "Epoch 7/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.1981 - accuracy: 0.3524\n",
            "Epoch 00007: val_loss did not improve from 2.32213\n",
            "547/547 [==============================] - 49s 90ms/step - loss: 2.1981 - accuracy: 0.3524 - val_loss: 2.3375 - val_accuracy: 0.3188\n",
            "Epoch 8/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.1574 - accuracy: 0.3618\n",
            "Epoch 00008: val_loss did not improve from 2.32213\n",
            "547/547 [==============================] - 49s 90ms/step - loss: 2.1574 - accuracy: 0.3618 - val_loss: 2.3493 - val_accuracy: 0.3126\n",
            "Epoch 9/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.1181 - accuracy: 0.3714\n",
            "Epoch 00009: val_loss did not improve from 2.32213\n",
            "547/547 [==============================] - 49s 90ms/step - loss: 2.1181 - accuracy: 0.3714 - val_loss: 2.3681 - val_accuracy: 0.3128\n",
            "Epoch 10/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.0752 - accuracy: 0.3836\n",
            "Epoch 00010: val_loss did not improve from 2.32213\n",
            "547/547 [==============================] - 49s 90ms/step - loss: 2.0752 - accuracy: 0.3836 - val_loss: 2.4167 - val_accuracy: 0.3050\n",
            "Epoch 11/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.0306 - accuracy: 0.3956\n",
            "Epoch 00011: val_loss did not improve from 2.32213\n",
            "547/547 [==============================] - 50s 92ms/step - loss: 2.0306 - accuracy: 0.3956 - val_loss: 2.4222 - val_accuracy: 0.3020\n",
            "Epoch 12/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 1.9832 - accuracy: 0.4086\n",
            "Epoch 00012: val_loss did not improve from 2.32213\n",
            "547/547 [==============================] - 51s 93ms/step - loss: 1.9832 - accuracy: 0.4086 - val_loss: 2.4637 - val_accuracy: 0.2966\n",
            "Epoch 13/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 1.9434 - accuracy: 0.4203\n",
            "Epoch 00013: val_loss did not improve from 2.32213\n",
            "547/547 [==============================] - 50s 91ms/step - loss: 1.9434 - accuracy: 0.4203 - val_loss: 2.5194 - val_accuracy: 0.2983\n",
            "Epoch 14/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 1.8981 - accuracy: 0.4338\n",
            "Epoch 00014: val_loss did not improve from 2.32213\n",
            "547/547 [==============================] - 50s 91ms/step - loss: 1.8981 - accuracy: 0.4338 - val_loss: 2.5470 - val_accuracy: 0.2897\n",
            "Epoch 15/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 1.8508 - accuracy: 0.4470\n",
            "Epoch 00015: val_loss did not improve from 2.32213\n",
            "547/547 [==============================] - 51s 92ms/step - loss: 1.8508 - accuracy: 0.4470 - val_loss: 2.5911 - val_accuracy: 0.2885\n",
            "Epoch 16/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 1.8113 - accuracy: 0.4547\n",
            "Epoch 00016: val_loss did not improve from 2.32213\n",
            "547/547 [==============================] - 53s 96ms/step - loss: 1.8113 - accuracy: 0.4547 - val_loss: 2.6389 - val_accuracy: 0.2890\n",
            "Epoch 00016: early stopping\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(10, 200), return_sequences=True)) #hidden state has 64 dims\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(128)) #hidden state has 64 dims\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(20, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "checkPoint = ModelCheckpoint('bestModel.h5', monitor='val_loss', verbose=True, save_best_only=True)\n",
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=True)\n",
        "hist = model.fit(embeddingMatrixTrain, trainLabels, epochs=50, batch_size=128,\n",
        "                 validation_data=(embeddingMatrixVal, validLabels), shuffle=True, callbacks=[checkPoint, earlyStopping])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TeDk09fJTwm",
        "outputId": "33871249-2095-4b5d-ef19-c16006a16e42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 9s 13ms/step - loss: 2.6290 - accuracy: 0.2891\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 2.3173 - accuracy: 0.3194\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[2.317291736602783, 0.319350004196167]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(embeddingMatrixTest, testLabels)\n",
        "model.load_weights('bestModel.h5')\n",
        "model.evaluate(embeddingMatrixTest, testLabels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OtodTApB9VhD",
        "outputId": "e413f4a5-54bd-4756-df93-8c2e0ad08542"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_20 (LSTM)              (None, 10, 128)           168448    \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 10, 128)           0         \n",
            "                                                                 \n",
            " lstm_21 (LSTM)              (None, 10, 64)            49408     \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 10, 64)            0         \n",
            "                                                                 \n",
            " lstm_22 (LSTM)              (None, 32)                12416     \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 20)                660       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 230,932\n",
            "Trainable params: 230,932\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.5934 - accuracy: 0.2648\n",
            "Epoch 00001: val_loss improved from inf to 2.42920, saving model to bestModel.h5\n",
            "547/547 [==============================] - 51s 83ms/step - loss: 2.5934 - accuracy: 0.2648 - val_loss: 2.4292 - val_accuracy: 0.2971\n",
            "Epoch 2/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.4541 - accuracy: 0.3000\n",
            "Epoch 00002: val_loss improved from 2.42920 to 2.39321, saving model to bestModel.h5\n",
            "547/547 [==============================] - 45s 82ms/step - loss: 2.4541 - accuracy: 0.3000 - val_loss: 2.3932 - val_accuracy: 0.3096\n",
            "Epoch 3/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.4105 - accuracy: 0.3079\n",
            "Epoch 00003: val_loss improved from 2.39321 to 2.36498, saving model to bestModel.h5\n",
            "547/547 [==============================] - 45s 82ms/step - loss: 2.4105 - accuracy: 0.3079 - val_loss: 2.3650 - val_accuracy: 0.3121\n",
            "Epoch 4/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.3779 - accuracy: 0.3159\n",
            "Epoch 00004: val_loss improved from 2.36498 to 2.35953, saving model to bestModel.h5\n",
            "547/547 [==============================] - 45s 82ms/step - loss: 2.3779 - accuracy: 0.3159 - val_loss: 2.3595 - val_accuracy: 0.3142\n",
            "Epoch 5/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.3486 - accuracy: 0.3228\n",
            "Epoch 00005: val_loss improved from 2.35953 to 2.35372, saving model to bestModel.h5\n",
            "547/547 [==============================] - 45s 82ms/step - loss: 2.3486 - accuracy: 0.3228 - val_loss: 2.3537 - val_accuracy: 0.3151\n",
            "Epoch 6/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.3211 - accuracy: 0.3299\n",
            "Epoch 00006: val_loss improved from 2.35372 to 2.34990, saving model to bestModel.h5\n",
            "547/547 [==============================] - 45s 82ms/step - loss: 2.3211 - accuracy: 0.3299 - val_loss: 2.3499 - val_accuracy: 0.3166\n",
            "Epoch 7/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.2951 - accuracy: 0.3368\n",
            "Epoch 00007: val_loss did not improve from 2.34990\n",
            "547/547 [==============================] - 45s 82ms/step - loss: 2.2951 - accuracy: 0.3368 - val_loss: 2.3516 - val_accuracy: 0.3146\n",
            "Epoch 8/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.2649 - accuracy: 0.3442\n",
            "Epoch 00008: val_loss did not improve from 2.34990\n",
            "547/547 [==============================] - 44s 81ms/step - loss: 2.2649 - accuracy: 0.3442 - val_loss: 2.3596 - val_accuracy: 0.3176\n",
            "Epoch 9/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.2346 - accuracy: 0.3514\n",
            "Epoch 00009: val_loss did not improve from 2.34990\n",
            "547/547 [==============================] - 44s 81ms/step - loss: 2.2346 - accuracy: 0.3514 - val_loss: 2.3731 - val_accuracy: 0.3164\n",
            "Epoch 10/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.2056 - accuracy: 0.3607\n",
            "Epoch 00010: val_loss did not improve from 2.34990\n",
            "547/547 [==============================] - 44s 81ms/step - loss: 2.2056 - accuracy: 0.3607 - val_loss: 2.3756 - val_accuracy: 0.3149\n",
            "Epoch 11/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.1714 - accuracy: 0.3697\n",
            "Epoch 00011: val_loss did not improve from 2.34990\n",
            "547/547 [==============================] - 44s 81ms/step - loss: 2.1714 - accuracy: 0.3697 - val_loss: 2.3975 - val_accuracy: 0.3114\n",
            "Epoch 12/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.1392 - accuracy: 0.3780\n",
            "Epoch 00012: val_loss did not improve from 2.34990\n",
            "547/547 [==============================] - 44s 81ms/step - loss: 2.1392 - accuracy: 0.3780 - val_loss: 2.4397 - val_accuracy: 0.3047\n",
            "Epoch 13/50\n",
            " 86/547 [===>..........................] - ETA: 35s - loss: 2.0721 - accuracy: 0.4022"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-37-21731bf311b8>\", line 14, in <module>\n",
            "    validation_data=(embeddingMatrixVal, validLabels), shuffle=True, callbacks=[checkPoint, earlyStopping])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1216, in fit\n",
            "    tmp_logs = self.train_function(iterator)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 910, in __call__\n",
            "    result = self._call(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 942, in _call\n",
            "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 3131, in __call__\n",
            "    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 1960, in _call_flat\n",
            "    ctx, args, cancellation_manager=cancellation_manager))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 603, in call\n",
            "    ctx=ctx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\n",
            "    inputs, attrs, num_outputs)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 725, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 709, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.7/posixpath.py\", line 383, in abspath\n",
            "    cwd = os.getcwd()\n",
            "FileNotFoundError: [Errno 2] No such file or directory\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(10, 200), return_sequences=True)) #hidden state has 64 dims\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(64, return_sequences=True)) #hidden state has 64 dims\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(32)) #hidden state has 64 dims\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(20, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "checkPoint = ModelCheckpoint('bestModel.h5', monitor='val_loss', verbose=True, save_best_only=True)\n",
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=True)\n",
        "hist = model.fit(embeddingMatrixTrain, trainLabels, epochs=50, batch_size=128,\n",
        "                 validation_data=(embeddingMatrixVal, validLabels), shuffle=True, callbacks=[checkPoint, earlyStopping])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcZ6MqpcRjrc",
        "outputId": "818110f7-19e3-4385-907a-a4061aab3a45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 9s 12ms/step - loss: 2.4514 - accuracy: 0.3044\n",
            "625/625 [==============================] - 7s 11ms/step - loss: 2.3405 - accuracy: 0.3189\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[2.3405096530914307, 0.31894999742507935]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(embeddingMatrixTest, testLabels)\n",
        "model.load_weights('bestModel.h5')\n",
        "model.evaluate(embeddingMatrixTest, testLabels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6fosU4VS7lW",
        "outputId": "7025eefa-c710-4a24-e081-c06fcbe6310b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_23 (LSTM)              (None, 10, 128)           168448    \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 10, 128)           0         \n",
            "                                                                 \n",
            " lstm_24 (LSTM)              (None, 10, 64)            49408     \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 10, 64)            0         \n",
            "                                                                 \n",
            " lstm_25 (LSTM)              (None, 32)                12416     \n",
            "                                                                 \n",
            " dropout_20 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 20)                660       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 230,932\n",
            "Trainable params: 230,932\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.5971 - accuracy: 0.2642\n",
            "Epoch 00001: val_loss improved from inf to 2.42883, saving model to bestModelLoss.h5\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.29876, saving model to bestModelAcc.h5\n",
            "547/547 [==============================] - 52s 84ms/step - loss: 2.5971 - accuracy: 0.2642 - val_loss: 2.4288 - val_accuracy: 0.2988\n",
            "Epoch 2/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.4540 - accuracy: 0.2997\n",
            "Epoch 00002: val_loss improved from 2.42883 to 2.39758, saving model to bestModelLoss.h5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.29876 to 0.30266, saving model to bestModelAcc.h5\n",
            "547/547 [==============================] - 47s 86ms/step - loss: 2.4540 - accuracy: 0.2997 - val_loss: 2.3976 - val_accuracy: 0.3027\n",
            "Epoch 3/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.4088 - accuracy: 0.3104\n",
            "Epoch 00003: val_loss improved from 2.39758 to 2.36552, saving model to bestModelLoss.h5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.30266 to 0.31105, saving model to bestModelAcc.h5\n",
            "547/547 [==============================] - 45s 82ms/step - loss: 2.4088 - accuracy: 0.3104 - val_loss: 2.3655 - val_accuracy: 0.3111\n",
            "Epoch 4/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.3785 - accuracy: 0.3164\n",
            "Epoch 00004: val_loss improved from 2.36552 to 2.35819, saving model to bestModelLoss.h5\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.31105 to 0.31385, saving model to bestModelAcc.h5\n",
            "547/547 [==============================] - 45s 83ms/step - loss: 2.3785 - accuracy: 0.3164 - val_loss: 2.3582 - val_accuracy: 0.3138\n",
            "Epoch 5/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.3520 - accuracy: 0.3241\n",
            "Epoch 00005: val_loss improved from 2.35819 to 2.35300, saving model to bestModelLoss.h5\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.31385 to 0.31525, saving model to bestModelAcc.h5\n",
            "547/547 [==============================] - 45s 83ms/step - loss: 2.3520 - accuracy: 0.3241 - val_loss: 2.3530 - val_accuracy: 0.3152\n",
            "Epoch 6/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.3238 - accuracy: 0.3305\n",
            "Epoch 00006: val_loss improved from 2.35300 to 2.34826, saving model to bestModelLoss.h5\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.31525 to 0.31835, saving model to bestModelAcc.h5\n",
            "547/547 [==============================] - 45s 83ms/step - loss: 2.3238 - accuracy: 0.3305 - val_loss: 2.3483 - val_accuracy: 0.3183\n",
            "Epoch 7/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.2960 - accuracy: 0.3361\n",
            "Epoch 00007: val_loss improved from 2.34826 to 2.34521, saving model to bestModelLoss.h5\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.31835\n",
            "547/547 [==============================] - 45s 82ms/step - loss: 2.2960 - accuracy: 0.3361 - val_loss: 2.3452 - val_accuracy: 0.3178\n",
            "Epoch 8/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.2682 - accuracy: 0.3430\n",
            "Epoch 00008: val_loss did not improve from 2.34521\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.31835\n",
            "547/547 [==============================] - 45s 82ms/step - loss: 2.2682 - accuracy: 0.3430 - val_loss: 2.3566 - val_accuracy: 0.3173\n",
            "Epoch 9/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.2354 - accuracy: 0.3518\n",
            "Epoch 00009: val_loss did not improve from 2.34521\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.31835 to 0.32024, saving model to bestModelAcc.h5\n",
            "547/547 [==============================] - 45s 82ms/step - loss: 2.2354 - accuracy: 0.3518 - val_loss: 2.3645 - val_accuracy: 0.3202\n",
            "Epoch 10/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.2054 - accuracy: 0.3599\n",
            "Epoch 00010: val_loss did not improve from 2.34521\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.32024\n",
            "547/547 [==============================] - 44s 81ms/step - loss: 2.2054 - accuracy: 0.3599 - val_loss: 2.3754 - val_accuracy: 0.3135\n",
            "Epoch 11/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.1724 - accuracy: 0.3686\n",
            "Epoch 00011: val_loss did not improve from 2.34521\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.32024\n",
            "547/547 [==============================] - 44s 81ms/step - loss: 2.1724 - accuracy: 0.3686 - val_loss: 2.3930 - val_accuracy: 0.3113\n",
            "Epoch 12/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.1394 - accuracy: 0.3785\n",
            "Epoch 00012: val_loss did not improve from 2.34521\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.32024\n",
            "547/547 [==============================] - 45s 82ms/step - loss: 2.1394 - accuracy: 0.3785 - val_loss: 2.4164 - val_accuracy: 0.3087\n",
            "Epoch 13/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.1054 - accuracy: 0.3906\n",
            "Epoch 00013: val_loss did not improve from 2.34521\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.32024\n",
            "547/547 [==============================] - 44s 81ms/step - loss: 2.1054 - accuracy: 0.3906 - val_loss: 2.4540 - val_accuracy: 0.3043\n",
            "Epoch 14/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.0721 - accuracy: 0.3976\n",
            "Epoch 00014: val_loss did not improve from 2.34521\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.32024\n",
            "547/547 [==============================] - 44s 81ms/step - loss: 2.0721 - accuracy: 0.3976 - val_loss: 2.4528 - val_accuracy: 0.3037\n",
            "Epoch 15/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.0360 - accuracy: 0.4087\n",
            "Epoch 00015: val_loss did not improve from 2.34521\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.32024\n",
            "547/547 [==============================] - 44s 81ms/step - loss: 2.0360 - accuracy: 0.4087 - val_loss: 2.5205 - val_accuracy: 0.3015\n",
            "Epoch 16/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.0045 - accuracy: 0.4156\n",
            "Epoch 00016: val_loss did not improve from 2.34521\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.32024\n",
            "547/547 [==============================] - 44s 81ms/step - loss: 2.0045 - accuracy: 0.4156 - val_loss: 2.5388 - val_accuracy: 0.2976\n",
            "Epoch 17/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 1.9747 - accuracy: 0.4234\n",
            "Epoch 00017: val_loss did not improve from 2.34521\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.32024\n",
            "547/547 [==============================] - 45s 81ms/step - loss: 1.9747 - accuracy: 0.4234 - val_loss: 2.5656 - val_accuracy: 0.2914\n",
            "Epoch 00017: early stopping\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(10, 200), return_sequences=True)) #hidden state has 64 dims\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(64, return_sequences=True)) #hidden state has 64 dims\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(32)) #hidden state has 64 dims\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(20, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "lossCheck = ModelCheckpoint('bestModelLoss.h5', monitor='val_loss', verbose=True, save_best_only=True)\n",
        "accCheck = ModelCheckpoint('bestModelAcc.h5', monitor='val_accuracy', verbose=True, save_best_only=True)\n",
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=True)\n",
        "hist = model.fit(embeddingMatrixTrain, trainLabels, epochs=50, batch_size=128,\n",
        "                 validation_data=(embeddingMatrixVal, validLabels), shuffle=True, callbacks=[lossCheck, accCheck, earlyStopping])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxjnW42tTJMd",
        "outputId": "0070b020-a456-4341-94ba-572dd716995f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 9s 12ms/step - loss: 2.5580 - accuracy: 0.2961\n",
            "625/625 [==============================] - 7s 12ms/step - loss: 2.3366 - accuracy: 0.3191\n",
            "625/625 [==============================] - 7s 12ms/step - loss: 2.3585 - accuracy: 0.3178\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[2.3585457801818848, 0.3177500069141388]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(embeddingMatrixTest, testLabels)\n",
        "model.load_weights('bestModelLoss.h5')\n",
        "model.evaluate(embeddingMatrixTest, testLabels)\n",
        "model.load_weights('bestModelAcc.h5')\n",
        "model.evaluate(embeddingMatrixTest, testLabels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qny55KwFY_3Q",
        "outputId": "b1ce3e3a-dd84-4a19-9722-61454dbab775"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_26 (LSTM)              (None, 10, 128)           168448    \n",
            "                                                                 \n",
            " dropout_21 (Dropout)        (None, 10, 128)           0         \n",
            "                                                                 \n",
            " lstm_27 (LSTM)              (None, 10, 64)            49408     \n",
            "                                                                 \n",
            " dropout_22 (Dropout)        (None, 10, 64)            0         \n",
            "                                                                 \n",
            " lstm_28 (LSTM)              (None, 32)                12416     \n",
            "                                                                 \n",
            " dropout_23 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 100)               3300      \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 100)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 20)                2020      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 235,592\n",
            "Trainable params: 235,592\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.6405 - accuracy: 0.2442\n",
            "Epoch 00001: val_loss improved from inf to 2.46828, saving model to bestModelLoss.h5\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.29037, saving model to bestModelAcc.h5\n",
            "547/547 [==============================] - 52s 85ms/step - loss: 2.6405 - accuracy: 0.2442 - val_loss: 2.4683 - val_accuracy: 0.2904\n",
            "Epoch 2/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.4915 - accuracy: 0.2851\n",
            "Epoch 00002: val_loss improved from 2.46828 to 2.41297, saving model to bestModelLoss.h5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.29037 to 0.29726, saving model to bestModelAcc.h5\n",
            "547/547 [==============================] - 45s 82ms/step - loss: 2.4915 - accuracy: 0.2851 - val_loss: 2.4130 - val_accuracy: 0.2973\n",
            "Epoch 3/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.4437 - accuracy: 0.3004\n",
            "Epoch 00003: val_loss improved from 2.41297 to 2.38541, saving model to bestModelLoss.h5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.29726 to 0.30745, saving model to bestModelAcc.h5\n",
            "547/547 [==============================] - 45s 83ms/step - loss: 2.4437 - accuracy: 0.3004 - val_loss: 2.3854 - val_accuracy: 0.3075\n",
            "Epoch 4/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.4116 - accuracy: 0.3072\n",
            "Epoch 00004: val_loss improved from 2.38541 to 2.37579, saving model to bestModelLoss.h5\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.30745 to 0.30825, saving model to bestModelAcc.h5\n",
            "547/547 [==============================] - 45s 83ms/step - loss: 2.4116 - accuracy: 0.3072 - val_loss: 2.3758 - val_accuracy: 0.3083\n",
            "Epoch 5/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.3871 - accuracy: 0.3134\n",
            "Epoch 00005: val_loss improved from 2.37579 to 2.36624, saving model to bestModelLoss.h5\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.30825 to 0.31325, saving model to bestModelAcc.h5\n",
            "547/547 [==============================] - 46s 83ms/step - loss: 2.3871 - accuracy: 0.3134 - val_loss: 2.3662 - val_accuracy: 0.3132\n",
            "Epoch 6/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.3632 - accuracy: 0.3174\n",
            "Epoch 00006: val_loss improved from 2.36624 to 2.36188, saving model to bestModelLoss.h5\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.31325 to 0.31715, saving model to bestModelAcc.h5\n",
            "547/547 [==============================] - 45s 83ms/step - loss: 2.3632 - accuracy: 0.3174 - val_loss: 2.3619 - val_accuracy: 0.3171\n",
            "Epoch 7/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.3354 - accuracy: 0.3266\n",
            "Epoch 00007: val_loss did not improve from 2.36188\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.31715\n",
            "547/547 [==============================] - 45s 82ms/step - loss: 2.3354 - accuracy: 0.3266 - val_loss: 2.3643 - val_accuracy: 0.3165\n",
            "Epoch 8/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.3124 - accuracy: 0.3305\n",
            "Epoch 00008: val_loss did not improve from 2.36188\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.31715\n",
            "547/547 [==============================] - 44s 81ms/step - loss: 2.3124 - accuracy: 0.3305 - val_loss: 2.3792 - val_accuracy: 0.3146\n",
            "Epoch 9/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.2802 - accuracy: 0.3393\n",
            "Epoch 00009: val_loss did not improve from 2.36188\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.31715\n",
            "547/547 [==============================] - 45s 82ms/step - loss: 2.2802 - accuracy: 0.3393 - val_loss: 2.3805 - val_accuracy: 0.3131\n",
            "Epoch 10/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.2530 - accuracy: 0.3453\n",
            "Epoch 00010: val_loss did not improve from 2.36188\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.31715\n",
            "547/547 [==============================] - 45s 82ms/step - loss: 2.2530 - accuracy: 0.3453 - val_loss: 2.3887 - val_accuracy: 0.3104\n",
            "Epoch 11/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.2211 - accuracy: 0.3555\n",
            "Epoch 00011: val_loss did not improve from 2.36188\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.31715\n",
            "547/547 [==============================] - 45s 82ms/step - loss: 2.2211 - accuracy: 0.3555 - val_loss: 2.4149 - val_accuracy: 0.3076\n",
            "Epoch 00011: early stopping\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(10, 200), return_sequences=True)) #hidden state has 64 dims\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(64, return_sequences=True)) #hidden state has 64 dims\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(32)) #hidden state has 64 dims\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(20, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "lossCheck = ModelCheckpoint('bestModelLoss.h5', monitor='val_loss', verbose=True, save_best_only=True)\n",
        "accCheck = ModelCheckpoint('bestModelAcc.h5', monitor='val_accuracy', verbose=True, save_best_only=True)\n",
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=5, verbose=True)\n",
        "hist = model.fit(embeddingMatrixTrain, trainLabels, epochs=50, batch_size=128,\n",
        "                 validation_data=(embeddingMatrixVal, validLabels), shuffle=True, callbacks=[lossCheck, accCheck, earlyStopping])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvnYt2KCZNTB",
        "outputId": "bcd92509-f5ff-43c9-b908-ffeacac887ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 9s 12ms/step - loss: 2.4109 - accuracy: 0.3092\n",
            "625/625 [==============================] - 7s 12ms/step - loss: 2.3533 - accuracy: 0.3153\n",
            "625/625 [==============================] - 7s 12ms/step - loss: 2.3533 - accuracy: 0.3153\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[2.3532633781433105, 0.3152500092983246]"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(embeddingMatrixTest, testLabels)\n",
        "model.load_weights('bestModelLoss.h5')\n",
        "model.evaluate(embeddingMatrixTest, testLabels)\n",
        "model.load_weights('bestModelAcc.h5')\n",
        "model.evaluate(embeddingMatrixTest, testLabels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qd0XA2H59ZCa",
        "outputId": "3812e2cb-9125-4f8d-eec2-9357a3ce716b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 3s 5ms/step - loss: 2.4530 - accuracy: 0.2957\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[2.4530069828033447, 0.29565000534057617]"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(embeddingMatrixTest, testLabels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dm0GSOf-IWg"
      },
      "outputs": [],
      "source": [
        "model.load_weights('bestModel.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMxf5K1r_J2L",
        "outputId": "0118a680-72fe-44ee-8667-293be4391aaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 3s 4ms/step - loss: 2.3620 - accuracy: 0.3084\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[2.3619701862335205, 0.3084000051021576]"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(embeddingMatrixTest, testLabels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMz81Gle_KKX",
        "outputId": "310478b0-7c21-4f4c-a46d-4cd9e33c3cfb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 10, 64)            29440     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 10, 64)            0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                33024     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 20)                1300      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 63,764\n",
            "Trainable params: 63,764\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(64, input_shape=(10, 50), return_sequences=True)) #hidden state has 64 dims\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(64, return_sequences=False))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(20, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViCw4eF6LpS8",
        "outputId": "f0c90292-bed4-42a3-cf6a-2cf85c7ef4f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.6050 - accuracy: 0.2535\n",
            "Epoch 00001: val_loss improved from inf to 2.47624, saving model to bestModel.h5\n",
            "547/547 [==============================] - 28s 41ms/step - loss: 2.6048 - accuracy: 0.2536 - val_loss: 2.4762 - val_accuracy: 0.2785\n",
            "Epoch 2/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.4917 - accuracy: 0.2804\n",
            "Epoch 00002: val_loss improved from 2.47624 to 2.44055, saving model to bestModel.h5\n",
            "547/547 [==============================] - 21s 38ms/step - loss: 2.4917 - accuracy: 0.2804 - val_loss: 2.4405 - val_accuracy: 0.2867\n",
            "Epoch 3/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.4573 - accuracy: 0.2891\n",
            "Epoch 00003: val_loss improved from 2.44055 to 2.41873, saving model to bestModel.h5\n",
            "547/547 [==============================] - 20s 37ms/step - loss: 2.4573 - accuracy: 0.2891 - val_loss: 2.4187 - val_accuracy: 0.2914\n",
            "Epoch 4/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.4329 - accuracy: 0.2942\n",
            "Epoch 00004: val_loss improved from 2.41873 to 2.40585, saving model to bestModel.h5\n",
            "547/547 [==============================] - 20s 36ms/step - loss: 2.4329 - accuracy: 0.2942 - val_loss: 2.4059 - val_accuracy: 0.2955\n",
            "Epoch 5/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.4118 - accuracy: 0.3012\n",
            "Epoch 00005: val_loss improved from 2.40585 to 2.38915, saving model to bestModel.h5\n",
            "547/547 [==============================] - 20s 36ms/step - loss: 2.4118 - accuracy: 0.3012 - val_loss: 2.3892 - val_accuracy: 0.2992\n",
            "Epoch 6/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.3973 - accuracy: 0.3041\n",
            "Epoch 00006: val_loss improved from 2.38915 to 2.38781, saving model to bestModel.h5\n",
            "547/547 [==============================] - 19s 34ms/step - loss: 2.3979 - accuracy: 0.3039 - val_loss: 2.3878 - val_accuracy: 0.3001\n",
            "Epoch 7/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.3820 - accuracy: 0.3067\n",
            "Epoch 00007: val_loss improved from 2.38781 to 2.37594, saving model to bestModel.h5\n",
            "547/547 [==============================] - 19s 34ms/step - loss: 2.3818 - accuracy: 0.3067 - val_loss: 2.3759 - val_accuracy: 0.3027\n",
            "Epoch 8/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.3727 - accuracy: 0.3108\n",
            "Epoch 00008: val_loss improved from 2.37594 to 2.37451, saving model to bestModel.h5\n",
            "547/547 [==============================] - 19s 34ms/step - loss: 2.3729 - accuracy: 0.3107 - val_loss: 2.3745 - val_accuracy: 0.3013\n",
            "Epoch 9/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.3621 - accuracy: 0.3135\n",
            "Epoch 00009: val_loss improved from 2.37451 to 2.37141, saving model to bestModel.h5\n",
            "547/547 [==============================] - 20s 36ms/step - loss: 2.3623 - accuracy: 0.3135 - val_loss: 2.3714 - val_accuracy: 0.3024\n",
            "Epoch 10/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.3524 - accuracy: 0.3152\n",
            "Epoch 00010: val_loss improved from 2.37141 to 2.36547, saving model to bestModel.h5\n",
            "547/547 [==============================] - 20s 36ms/step - loss: 2.3524 - accuracy: 0.3152 - val_loss: 2.3655 - val_accuracy: 0.3030\n",
            "Epoch 11/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.3471 - accuracy: 0.3161\n",
            "Epoch 00011: val_loss improved from 2.36547 to 2.36350, saving model to bestModel.h5\n",
            "547/547 [==============================] - 20s 37ms/step - loss: 2.3470 - accuracy: 0.3161 - val_loss: 2.3635 - val_accuracy: 0.3056\n",
            "Epoch 12/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.3361 - accuracy: 0.3188\n",
            "Epoch 00012: val_loss did not improve from 2.36350\n",
            "547/547 [==============================] - 19s 35ms/step - loss: 2.3361 - accuracy: 0.3188 - val_loss: 2.3638 - val_accuracy: 0.3083\n",
            "Epoch 13/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.3274 - accuracy: 0.3198\n",
            "Epoch 00013: val_loss improved from 2.36350 to 2.36088, saving model to bestModel.h5\n",
            "547/547 [==============================] - 20s 36ms/step - loss: 2.3275 - accuracy: 0.3197 - val_loss: 2.3609 - val_accuracy: 0.3071\n",
            "Epoch 14/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.3245 - accuracy: 0.3201\n",
            "Epoch 00014: val_loss improved from 2.36088 to 2.35889, saving model to bestModel.h5\n",
            "547/547 [==============================] - 21s 38ms/step - loss: 2.3246 - accuracy: 0.3201 - val_loss: 2.3589 - val_accuracy: 0.3055\n",
            "Epoch 15/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.3152 - accuracy: 0.3237\n",
            "Epoch 00015: val_loss did not improve from 2.35889\n",
            "547/547 [==============================] - 19s 35ms/step - loss: 2.3153 - accuracy: 0.3236 - val_loss: 2.3617 - val_accuracy: 0.3063\n",
            "Epoch 16/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.3079 - accuracy: 0.3248\n",
            "Epoch 00016: val_loss did not improve from 2.35889\n",
            "547/547 [==============================] - 19s 35ms/step - loss: 2.3079 - accuracy: 0.3248 - val_loss: 2.3592 - val_accuracy: 0.3082\n",
            "Epoch 17/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.3030 - accuracy: 0.3257\n",
            "Epoch 00017: val_loss did not improve from 2.35889\n",
            "547/547 [==============================] - 19s 35ms/step - loss: 2.3030 - accuracy: 0.3257 - val_loss: 2.3642 - val_accuracy: 0.3096\n",
            "Epoch 18/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.2938 - accuracy: 0.3288\n",
            "Epoch 00018: val_loss did not improve from 2.35889\n",
            "547/547 [==============================] - 19s 35ms/step - loss: 2.2938 - accuracy: 0.3288 - val_loss: 2.3600 - val_accuracy: 0.3099\n",
            "Epoch 19/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.2884 - accuracy: 0.3298\n",
            "Epoch 00019: val_loss did not improve from 2.35889\n",
            "547/547 [==============================] - 20s 36ms/step - loss: 2.2884 - accuracy: 0.3298 - val_loss: 2.3711 - val_accuracy: 0.3058\n",
            "Epoch 20/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.2814 - accuracy: 0.3316\n",
            "Epoch 00020: val_loss did not improve from 2.35889\n",
            "547/547 [==============================] - 20s 37ms/step - loss: 2.2813 - accuracy: 0.3317 - val_loss: 2.3715 - val_accuracy: 0.3080\n",
            "Epoch 21/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.2776 - accuracy: 0.3320\n",
            "Epoch 00021: val_loss did not improve from 2.35889\n",
            "547/547 [==============================] - 20s 37ms/step - loss: 2.2777 - accuracy: 0.3321 - val_loss: 2.3670 - val_accuracy: 0.3076\n",
            "Epoch 22/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.2681 - accuracy: 0.3343\n",
            "Epoch 00022: val_loss did not improve from 2.35889\n",
            "547/547 [==============================] - 19s 35ms/step - loss: 2.2679 - accuracy: 0.3344 - val_loss: 2.3682 - val_accuracy: 0.3044\n",
            "Epoch 23/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.2670 - accuracy: 0.3353\n",
            "Epoch 00023: val_loss did not improve from 2.35889\n",
            "547/547 [==============================] - 19s 35ms/step - loss: 2.2670 - accuracy: 0.3353 - val_loss: 2.3770 - val_accuracy: 0.3081\n",
            "Epoch 24/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.2586 - accuracy: 0.3382\n",
            "Epoch 00024: val_loss did not improve from 2.35889\n",
            "547/547 [==============================] - 19s 35ms/step - loss: 2.2586 - accuracy: 0.3382 - val_loss: 2.3750 - val_accuracy: 0.3068\n",
            "Epoch 25/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.2526 - accuracy: 0.3391\n",
            "Epoch 00025: val_loss did not improve from 2.35889\n",
            "547/547 [==============================] - 20s 36ms/step - loss: 2.2526 - accuracy: 0.3391 - val_loss: 2.3802 - val_accuracy: 0.3037\n",
            "Epoch 26/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.2473 - accuracy: 0.3419\n",
            "Epoch 00026: val_loss did not improve from 2.35889\n",
            "547/547 [==============================] - 21s 38ms/step - loss: 2.2472 - accuracy: 0.3419 - val_loss: 2.3805 - val_accuracy: 0.3077\n",
            "Epoch 27/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.2429 - accuracy: 0.3429\n",
            "Epoch 00027: val_loss did not improve from 2.35889\n",
            "547/547 [==============================] - 20s 36ms/step - loss: 2.2429 - accuracy: 0.3429 - val_loss: 2.3911 - val_accuracy: 0.3041\n",
            "Epoch 28/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.2367 - accuracy: 0.3445\n",
            "Epoch 00028: val_loss did not improve from 2.35889\n",
            "547/547 [==============================] - 19s 35ms/step - loss: 2.2366 - accuracy: 0.3444 - val_loss: 2.3939 - val_accuracy: 0.3079\n",
            "Epoch 29/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.2313 - accuracy: 0.3461\n",
            "Epoch 00029: val_loss did not improve from 2.35889\n",
            "547/547 [==============================] - 19s 35ms/step - loss: 2.2313 - accuracy: 0.3461 - val_loss: 2.3912 - val_accuracy: 0.3050\n",
            "Epoch 30/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.2270 - accuracy: 0.3467\n",
            "Epoch 00030: val_loss did not improve from 2.35889\n",
            "547/547 [==============================] - 19s 35ms/step - loss: 2.2268 - accuracy: 0.3466 - val_loss: 2.3967 - val_accuracy: 0.3036\n",
            "Epoch 31/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.2194 - accuracy: 0.3475\n",
            "Epoch 00031: val_loss did not improve from 2.35889\n",
            "547/547 [==============================] - 20s 37ms/step - loss: 2.2194 - accuracy: 0.3475 - val_loss: 2.3959 - val_accuracy: 0.3023\n",
            "Epoch 32/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.2161 - accuracy: 0.3495\n",
            "Epoch 00032: val_loss did not improve from 2.35889\n",
            "547/547 [==============================] - 23s 43ms/step - loss: 2.2158 - accuracy: 0.3495 - val_loss: 2.4030 - val_accuracy: 0.3040\n",
            "Epoch 33/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.2104 - accuracy: 0.3511\n",
            "Epoch 00033: val_loss did not improve from 2.35889\n",
            "547/547 [==============================] - 22s 40ms/step - loss: 2.2104 - accuracy: 0.3511 - val_loss: 2.3995 - val_accuracy: 0.3057\n",
            "Epoch 34/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.2065 - accuracy: 0.3524\n",
            "Epoch 00034: val_loss did not improve from 2.35889\n",
            "547/547 [==============================] - 21s 39ms/step - loss: 2.2065 - accuracy: 0.3524 - val_loss: 2.4107 - val_accuracy: 0.3012\n",
            "Epoch 35/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.1993 - accuracy: 0.3538\n",
            "Epoch 00035: val_loss did not improve from 2.35889\n",
            "547/547 [==============================] - 20s 36ms/step - loss: 2.1994 - accuracy: 0.3538 - val_loss: 2.4263 - val_accuracy: 0.3007\n",
            "Epoch 36/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.1951 - accuracy: 0.3555\n",
            "Epoch 00036: val_loss did not improve from 2.35889\n",
            "547/547 [==============================] - 20s 36ms/step - loss: 2.1952 - accuracy: 0.3555 - val_loss: 2.4163 - val_accuracy: 0.3014\n",
            "Epoch 37/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.1909 - accuracy: 0.3569\n",
            "Epoch 00037: val_loss did not improve from 2.35889\n",
            "547/547 [==============================] - 20s 36ms/step - loss: 2.1913 - accuracy: 0.3568 - val_loss: 2.4202 - val_accuracy: 0.3000\n",
            "Epoch 38/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.1816 - accuracy: 0.3603\n",
            "Epoch 00038: val_loss did not improve from 2.35889\n",
            "547/547 [==============================] - 20s 37ms/step - loss: 2.1816 - accuracy: 0.3603 - val_loss: 2.4254 - val_accuracy: 0.3036\n",
            "Epoch 39/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.1819 - accuracy: 0.3596\n",
            "Epoch 00039: val_loss did not improve from 2.35889\n",
            "547/547 [==============================] - 20s 37ms/step - loss: 2.1819 - accuracy: 0.3596 - val_loss: 2.4364 - val_accuracy: 0.2990\n",
            "Epoch 40/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.1725 - accuracy: 0.3621\n",
            "Epoch 00040: val_loss did not improve from 2.35889\n",
            "547/547 [==============================] - 20s 37ms/step - loss: 2.1727 - accuracy: 0.3621 - val_loss: 2.4411 - val_accuracy: 0.3023\n",
            "Epoch 41/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.1700 - accuracy: 0.3628\n",
            "Epoch 00041: val_loss did not improve from 2.35889\n",
            "547/547 [==============================] - 20s 37ms/step - loss: 2.1700 - accuracy: 0.3627 - val_loss: 2.4472 - val_accuracy: 0.2984\n",
            "Epoch 42/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.1653 - accuracy: 0.3628\n",
            "Epoch 00042: val_loss did not improve from 2.35889\n",
            "547/547 [==============================] - 21s 38ms/step - loss: 2.1649 - accuracy: 0.3629 - val_loss: 2.4496 - val_accuracy: 0.2983\n",
            "Epoch 43/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.1587 - accuracy: 0.3650\n",
            "Epoch 00043: val_loss did not improve from 2.35889\n",
            "547/547 [==============================] - 20s 36ms/step - loss: 2.1587 - accuracy: 0.3650 - val_loss: 2.4463 - val_accuracy: 0.2991\n",
            "Epoch 44/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.1570 - accuracy: 0.3664\n",
            "Epoch 00044: val_loss did not improve from 2.35889\n",
            "547/547 [==============================] - 19s 35ms/step - loss: 2.1570 - accuracy: 0.3664 - val_loss: 2.4592 - val_accuracy: 0.2985\n",
            "Epoch 45/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.1516 - accuracy: 0.3697\n",
            "Epoch 00045: val_loss did not improve from 2.35889\n",
            "547/547 [==============================] - 20s 36ms/step - loss: 2.1516 - accuracy: 0.3695 - val_loss: 2.4632 - val_accuracy: 0.2966\n",
            "Epoch 46/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.1468 - accuracy: 0.3686\n",
            "Epoch 00046: val_loss did not improve from 2.35889\n",
            "547/547 [==============================] - 20s 36ms/step - loss: 2.1468 - accuracy: 0.3686 - val_loss: 2.4719 - val_accuracy: 0.2985\n",
            "Epoch 47/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.1421 - accuracy: 0.3694\n",
            "Epoch 00047: val_loss did not improve from 2.35889\n",
            "547/547 [==============================] - 20s 37ms/step - loss: 2.1421 - accuracy: 0.3694 - val_loss: 2.4898 - val_accuracy: 0.2989\n",
            "Epoch 48/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.1386 - accuracy: 0.3707\n",
            "Epoch 00048: val_loss did not improve from 2.35889\n",
            "547/547 [==============================] - 21s 38ms/step - loss: 2.1386 - accuracy: 0.3707 - val_loss: 2.4801 - val_accuracy: 0.2988\n",
            "Epoch 49/50\n",
            "546/547 [============================>.] - ETA: 0s - loss: 2.1341 - accuracy: 0.3731\n",
            "Epoch 00049: val_loss did not improve from 2.35889\n",
            "547/547 [==============================] - 20s 36ms/step - loss: 2.1342 - accuracy: 0.3730 - val_loss: 2.4854 - val_accuracy: 0.2953\n",
            "Epoch 50/50\n",
            "547/547 [==============================] - ETA: 0s - loss: 2.1284 - accuracy: 0.3743\n",
            "Epoch 00050: val_loss did not improve from 2.35889\n",
            "547/547 [==============================] - 20s 37ms/step - loss: 2.1284 - accuracy: 0.3743 - val_loss: 2.4837 - val_accuracy: 0.2968\n"
          ]
        }
      ],
      "source": [
        "checkPoint = ModelCheckpoint('bestModel.h5', monitor='val_loss', verbose=True, save_best_only=True)\n",
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=True)\n",
        "hist = model.fit(embeddingMatrixTrain, trainLabels, epochs=50, batch_size=128,\n",
        "                 validation_data=(embeddingMatrixVal, validLabels), shuffle=True, callbacks=[checkPoint])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_tviTp1LsDu",
        "outputId": "44ac8684-f61d-4da7-e0d1-dcb15b53d902"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 6s 7ms/step - loss: 2.4827 - accuracy: 0.2964\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[2.482708215713501, 0.2964000105857849]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(embeddingMatrixTest, testLabels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcW27tpvLv_8"
      },
      "outputs": [],
      "source": [
        "model.load_weights('bestModel.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8zJwX7dLwWf",
        "outputId": "ef1ecf03-ecd7-4b35-fdfb-b307be609365"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 5s 7ms/step - loss: 2.3595 - accuracy: 0.3091\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[2.359462022781372, 0.3091000020503998]"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(embeddingMatrixTest, testLabels)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "emoji_lstm.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
